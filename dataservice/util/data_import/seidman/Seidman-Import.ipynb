{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = '/Users/singhn4/Projects/kids_first/data/Seidman_2015'\n",
    "DBGAP_DIR = os.path.join(DATA_DIR, 'dbgap')\n",
    "ALIQUOT_SHIP_DIR = os.path.join(DATA_DIR, 'manifests', 'shipping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction - Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def dropna_rows_cols(df_func):\n",
    "    \"\"\"\n",
    "    Decorator to drop rows and cols w all nan values\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        df = df_func(*args, **kwargs)\n",
    "\n",
    "        # None or empty df\n",
    "        try:\n",
    "            if df.empty:\n",
    "                return df\n",
    "        except AttributeError:\n",
    "            return df\n",
    "\n",
    "        # Rows\n",
    "        df.dropna(how=\"all\", inplace=True)\n",
    "        # Cols\n",
    "        df.dropna(how=\"all\", axis=1, inplace=True)\n",
    "        # Replace NaN values with None\n",
    "        df = df.where((pd.notnull(df)), None)\n",
    "        return df\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "def reformat_column_names(df_func):\n",
    "    \"\"\"\n",
    "    Decorator to reformat DataFrame column names.\n",
    "\n",
    "    Replace all column names having whitespace with underscore\n",
    "    and make lowercase\n",
    "    \"\"\"\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        df = df_func(*args, **kwargs)\n",
    "        # None or empty df\n",
    "        try:\n",
    "            if df.empty:\n",
    "                return df\n",
    "        except AttributeError:\n",
    "            return df\n",
    "        df.columns = map((lambda x: x.replace(\" \", \"_\").lower()),\n",
    "                         df.columns)\n",
    "        return df\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_study_file_data(filepaths=None):\n",
    "    \"\"\"\n",
    "    Read in raw study files\n",
    "    \"\"\"\n",
    "    if not filepaths:\n",
    "        filepaths = os.listdir(DBGAP_DIR)\n",
    "\n",
    "    study_files = [{\"study_file_name\": f}\n",
    "                   for f in filepaths if 'dbGaP' in f]\n",
    "    return pd.DataFrame(study_files)\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_study_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read study data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR,\n",
    "                                'study.txt')\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_investigator_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read investigator data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR,\n",
    "                                'investigator.txt')\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_family_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read family data for all participants\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR,\n",
    "                                '7a_dbGaP_PedigreeDS.txt')\n",
    "    df = pd.read_csv(filepath,\n",
    "                     delimiter='\\t',\n",
    "                     dtype={'SUBJID': str})\n",
    "    # Subset of columns\n",
    "    df.drop(['SEX'], axis=1, inplace=True)\n",
    "\n",
    "    # Add proband column\n",
    "    def func(row): return bool(row['MOTHER'] and row['FATHER'])\n",
    "    df['is_proband'] = df.apply(func, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes']\n",
      "['None' 'No' 'Yes']\n",
      "['None' 'No' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'abnormal fetal calvarium'\n",
      " 'Dolichocephaly with bony synostosis of sagittal structure.'\n",
      " 'dolichochocehaly' 'unilateral coronal synostosis']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'frontal bossing (occipital protuberance)'\n",
      " 'cephalohematoma, Caput Succedaneum'\n",
      " 'short, sloping forehead with prominent occiput' 'bitemporal hallowing'\n",
      " 'small anterior fontanelle' 'congenital scar from eye to scalp per Mom'\n",
      " 'brachycephaly' 'parietal encephalocele, plagiocephaly'\n",
      " 'overriding coronal sutures'\n",
      " 'medical record indicates that she had a cyst in her brain'\n",
      " 'narrow forehead' 'metopic prominence' 'plagiocephaly' 'Plagiocephaly'\n",
      " 'sloped forehead, narrow' 'flat face' '3 fontanelles'\n",
      " 'Plagiocephaly, triangular shaped in coronal plane' 'bitemporal narrowing']\n",
      "['None' 'No' 'Yes']\n",
      "['Unknown' 'None' 'No/Not checked']\n",
      "['Unknown' 'None' 'No/Not checked' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'No/Not checked' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'No/Not checked' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'No/Not checked' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Glaucoma' 'myopia' 'intraretinal hemorrhages'\n",
      " 'mildly proptotic eyes' 'bilateral low vision' 'sclerae anicteric'\n",
      " 'downslanting' 'Exotropia' 'short palpebral fissures'\n",
      " 'left microphthalmia' 'proptotic, long eyelashes' 'Belpharoptosis'\n",
      " 'Microphthalmia and cloudy corneas'\n",
      " 'prominant eyes, long eyelashes, midface hypoplasia' 'epibulbar dermoid'\n",
      " 'downslanting palepbral fissures' 'hypertelorism' 'mild ROP OU'\n",
      " 'upslanting palpebrals' 'slightly upslanted palpebral fissures'\n",
      " 'palpebral fissures' 'eye deviation\"\" per  note' 'Amblyopia'\n",
      " 'Hypotelorism, downslanted palpebral fissures'\n",
      " 'hypotelorism, downslanting papebral fissures' 'amblyopia'\n",
      " 'Born with retinoblastoma']\n",
      "['None' 'No' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'No/Not checked' 'Yes']\n",
      "['Unknown' 'None' 'No/Not checked' 'Yes']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Atresia of left external ear'\n",
      " 'R ear overfolded and posteriorly rotated; L ear slightly pointed'\n",
      " 'cupped ears' 'pointy superiorly' 'small' 'slight redundancy in helices'\n",
      " 'rail road track deformity' 'Bilateral glue ear'\n",
      " 'overriding helices and relatively small' 'squared helix'\n",
      " 'Bilateral Congenital Ossicular Anomaly' 'prominent'\n",
      " 'R ear long and underdeveloped' 'posteriorly rotated'\n",
      " 'Underdeveloped ears' 'pointy' 'enlarged' 'overfolded superior helices'\n",
      " 'Left ear microtia' 'Posteriorly rotated' 'r ear is smaller in size'\n",
      " 'posteriorly set' 'thick helices' 'congenital deafness, R pinna cupped.']\n",
      "['None' 'No' 'Yes']\n",
      "['None' 'No' 'Yes']\n",
      "['Unknown' 'None' 'No/Not checked']\n",
      "['Unknown' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Torticollis' 'torticollis' 'short neck'\n",
      " 'neck bent to one side;needed PT' 'short' 'cystic hygroma' 'mildly short'\n",
      " 'short, thick' 'Short']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Short frenulum, hypoplastic left mandible' 'tongue-tied' 'thrush'\n",
      " 'ankyloglossia' 'asymmetric' 'small' 'thin upper lip'\n",
      " 'small mouth,thin upper lip' 'missing teeth'\n",
      " 'small maxilla/mandible on right side' 'thin lips, short philtrum'\n",
      " 'Asymmetric mouth movement; hypoplastic left jaw']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'high palate' 'high arched' 'high arched and narrowed'\n",
      " 'mildly high-arched']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'stridor, left vocal cord paralysis' 'esophagitis.  G-tube.'\n",
      " 'hypoplastic right side, anteriorly displaced' 'Asthma'\n",
      " 'esophageal reflux']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['None' 'sternum asymmetry']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'asthma' 'scimitar syndrome' 'small lungs'\n",
      " 'pulmonary lymphangiectasia' 'pulmonary hypertension'\n",
      " 'hypoplasia L mainstem bronchus'\n",
      " 'pulmonary hypertension in newborn period'\n",
      " 'CHRONIC LUNG DISEASE-PREMATURITY'\n",
      " 'Frequent episodes of migratory atelectasis'\n",
      " 'reversed pulmonary anatomy (L-sided on R, R on L)'\n",
      " 'inverted bronchial pattern']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' '3 cm. liver' 'enlarged tranverse liver' 'Liver hepatomegaly'\n",
      " 'infantile hepatic hemangioma' 'indirect hyperbilirubinemia'\n",
      " 'portacaval shunt']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'heterotaxy' 'Gastroesophageal reflux'\n",
      " 'Protein-losing enteropathy: Celiac confirmed' 'cecal carcinoma'\n",
      " 'deformity of the right anterolateral abdominal wall' '2 vessel cord'\n",
      " '2 vessel umbilical cord' 'pancreas not seen on ultrasound'\n",
      " 'Hernia, type unk' 'stricture or obstruction and medical NEC'\n",
      " 'Moragni hernia' 'heterotaxy syndrome' 'ileal atresia'\n",
      " 'Protein Losing Enteropathy' 'hernia x2 type unk' 'right-sided stomach'\n",
      " 'rt-sided stomach' 'esophageal atresai' 'cholecystectomy  1994'\n",
      " 'rt-sided stomach & rt-sided multi-lobulated spleen'\n",
      " 'Atresia of the large intestine' 'Pancreatitis' 'GERD' 'situs inversus']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Pyelectasis' 'Hypoplastic'\n",
      " 'non-functioning Rt. kidney, obstruction of bladder outlet, hydroureteral nephrosis of the Lt. kidney'\n",
      " 'L ureterocele with absent R kidney' 'R and L kidneys pelvicaliectasis'\n",
      " 'left pyelectasis' 'double left renal collecting systems and ureters'\n",
      " 'double kidney' 'mild upper pole caliectasis'\n",
      " 'ureteropelvic junction obstruction' 'Chronic renal insufficiency'\n",
      " 'Small right kidney' 'R KIDNEY IS ABSENT' 'hyperechoic renal cortex'\n",
      " 'ureterocele, Right vesicoureteric reflux, grade 1' 'pelviectasis'\n",
      " 'rectourethral fistula' 'renal agenesis' 'hypoplasia of kidney']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'meatus stenosis' 'chordee' 'phimosis' 'rectovaginal fistula'\n",
      " 'hydrocele' 'labial adhesions' 'Hydrocele' 'high riding testicles'\n",
      " 'neurogenic bladder' 'ventral displacement of meatus' 'hydroceles'\n",
      " 'rectovestibular fistula' 'hypogonadotropic hypogonadism'\n",
      " 'varicoceles and phimosis.' 'prominent labia']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'spina bifida'\n",
      " 'asymmetric sacral cleft, low lying conus terminalis L3' 'hemi-vertebrae'\n",
      " 'Klippel-Feil syndrome'\n",
      " 'sacral agenesis with absent coccyx and missing vertebrae at S1'\n",
      " 'abnormal cervical and thoracic bodies' 'absent sacrum and lumbar spine'\n",
      " 'incompletely formed T10' 'segmental abnormality of sacrum'\n",
      " 'left sided hemivertebrae'\n",
      " 'segmental anomalies involving upper thoracic spine']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Thoracic spinal cord syrinx' 'Congenital hemivertebra'\n",
      " 'stiff musculature' 'thickened rib, mild scoliosis, difuse osteopenia'\n",
      " 'Osteopenia (updated )' 'Spina bifida' 'tibial torsion,'\n",
      " 'Right sided Sternocleidomastoid Contracture' 'short stature'\n",
      " 'shortened long bones' 'asymmetrical gluteal crease'\n",
      " 'underdeveloped pelvis, lower extremity contractures'\n",
      " 'low lying conus at S1-2 w/ fatty filum'\n",
      " 'short achilles tendon on one side'\n",
      " 'leg length discrepancy and short stature' 'short sternum'\n",
      " 'mild ligamentous laxity' 'shallow acetabula' 'idiopathic short stature'\n",
      " 'sacral hemangioma'\n",
      " 'no humerus, radius/ulna or hand bones on the left side'\n",
      " 'hypotonia lower extremities']\n",
      "['None' 'Yes' 'No']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'Yes' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Clinodactyly, right hand' 'mildly hypoplastic proximal thumbs'\n",
      " 'clinodactyly 5th finger' 'hypoplastic left thumb' 'tapering fingers'\n",
      " 'left transverse crease'\n",
      " 'bilateral clinodactyly 5th fingers, left hand simian creases'\n",
      " 'decreased thenar eminence' 'clubbing'\n",
      " 'skintags after the 5th digit on each hand.'\n",
      " 'underdeveloped thenar prominence'\n",
      " 'distal limb deformities and radial anomaly'\n",
      " 'Left hand single palmar crease, clinodactyly'\n",
      " 'no humerus, radius/ulna or hand bones on the left side']\n",
      "['None' 'Yes' 'No']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'Yes' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'short toe bones 4th/5th digits' 'Broad big toe'\n",
      " 'metatarsus adductus bilaterally' 'bilat toes 2-4 syndactyly'\n",
      " 'clindactyly of fifth digits, L partial simian crease' 'Tarsal Coalition'\n",
      " 'extra digit bilat' 'overlapping toes on right: 4th overlaps 5th'\n",
      " 'hallux valgus']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'learning disability, ADHD' 'LS Myelomeningocele' 'seizures'\n",
      " 'monoparesis of right arm' 'developmental & learning issues' 'PVL'\n",
      " 'Gross motor delay' 'Hypertonic' 'choroid plexus cyst'\n",
      " 'Assymetric crying facies' 'anxiety disorder' 'Seizure disorder.'\n",
      " 'Agenesis of corpus callosum' 'cerebral atrophy' 'low muscle tone'\n",
      " 'hamartoma' 'sinus dermal tract'\n",
      " 'pericallsol lipoma; splenium of corpus callosum'\n",
      " 'severe developmental delay'\n",
      " 'severe developmental delay, non-verbal, autistic, history of seizures'\n",
      " 'Congenital Bulbar Palsy' 'parietal encephalocele'\n",
      " 'global developmental delay, hypotonia' 'Caudal regression syndrome'\n",
      " 'hypotonia' 'muscle tone' 'mild global developmental delay'\n",
      " 'hypotonia, pt with head lag, cannot sit on her own' 'severe seizures'\n",
      " 'hypoplastic corpus callosum, vermis hypoplasia'\n",
      " 'seizures related to hypocalcemia' 'polymicrogyria' 'HORNER SYNDROME'\n",
      " 'seizure disorder' 'stroke and seizure per physician note '\n",
      " 'tethered cord malformation sequence' 'periventricular leukomalacia'\n",
      " 'subject has CP.' 'hemiplegic cerebral palsy; abnormal gait']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'skin tag on lower part of sternum' '3 facial skin tags'\n",
      " 'left sided auricular skin tags as well as one tag on left cheek.'\n",
      " 'very dry skin\"\"' 'anal skin tag']\n",
      "['None' 'No' 'Yes']\n",
      "['None' 'congenital hypoglycemia' 'Hypothyroidism, Vit D deficiency'\n",
      " 'hypothyroid' 'late onset of puberty/growth hormone deficiency'\n",
      " 'Hypothyroidism (update )' 'congenital hypothyroidism' 'short stature'\n",
      " 'Hypothyroidism' 'central hypothyrodism' 'hypercholesterolemia'\n",
      " 'hypothyroidism' 'hypothyroidism, hyperbilirubinemia'\n",
      " 'hypoglycemia, hypoparathyroidism'\n",
      " 'delayed puberty-no facial hair,pubic or underarm hair.'\n",
      " 'low growth factor/idiopathic short stature' 'pheochromocytoma   surgery '\n",
      " 'hypoglycemia']\n",
      "['None' 'No' 'Yes']\n",
      "['None' 'Hypoplastic' 'Absent' 'Other']\n",
      "['None' 'very small']\n",
      "['None' 'No' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'anemia' 'Factor V Leiden' 'Factor XII deficiency'\n",
      " 'thrombocytopenia' 'ANEMIA OF PREMATURITY'\n",
      " 'Factor V Leiden heterozygous, MTHFR heterozygous' 'hypogammaglobulinemia'\n",
      " 'decrease vit K and Factor XII deficiency']\n",
      "['No' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked' 'Yes']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['None']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['Not applicable' 'None' 'No/Not checked']\n",
      "['Not applicable' 'None' 'Yes' 'No/Not checked']\n",
      "['None' 'Homozygous familial hypercholesterolemia'\n",
      " 'alpha and beta Thalassemia trait']\n",
      "['None' 'No' 'Yes']\n",
      "['None' 'Immune Globulin deficiency for unknown reasons'\n",
      " 'Exposed to toxoplasma in utero - born negative'\n",
      " 'juvenile rheumatoid arthritis']\n"
     ]
    }
   ],
   "source": [
    "# Find the potential negative/positive observed vaue\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "filepath = os.path.join(DBGAP_DIR, '3a_dbGaP_SubjectPhenotypes_ExtracardiacFindingsDS.txt')\n",
    "\n",
    "# Read csv\n",
    "df = pd.read_csv(filepath,\n",
    "             delimiter='\\t',\n",
    "             dtype={'SUBJID': str})\n",
    "\n",
    "cols = df.columns.tolist()[1:]\n",
    "for col in cols:\n",
    "    if not is_numeric_dtype(df[col]):\n",
    "        print(df[col].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_phenotype_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read phenotype data\n",
    "    \"\"\"\n",
    "    # Read in cached phenotypes or create if they don't exist\n",
    "    hpo_fp = os.path.join(DATA_DIR, 'phenotype_hpo_mapping.txt')\n",
    "    if os.path.exists(hpo_fp):\n",
    "        return pd.read_csv(hpo_fp,dtype={'SUBJID': str})\n",
    "        \n",
    "    filepath = os.path.join(\n",
    "    DBGAP_DIR,\n",
    "    '3a_dbGaP_SubjectPhenotypes_ExtracardiacFindingsDS.txt')\n",
    "\n",
    "    # Read csv\n",
    "    df = pd.read_csv(filepath,\n",
    "                     delimiter='\\t',\n",
    "                     dtype={'SUBJID': str})\n",
    "\n",
    "    # Convert age years to days\n",
    "    df['LATEST_EXAM_AGE'] = df[\"LATEST_EXAM_AGE\"].apply(\n",
    "        lambda x: int(x) * 365)\n",
    "    age_at_event_days = df[['LATEST_EXAM_AGE', 'SUBJID']]\n",
    "\n",
    "    # Select string based phenotypes\n",
    "    df = df.select_dtypes(include='object')\n",
    "\n",
    "    # Make all values lower case\n",
    "    for col in df.columns.tolist():\n",
    "        df[col] = df[col].apply(lambda x: str(x).lower())\n",
    "\n",
    "    # Reshape to build the phenotypes df\n",
    "    cols = df.columns.tolist()[2:]\n",
    "    phenotype_cols = [col for col in cols if not col.startswith('OTHER')]\n",
    "    phenotype_df = pd.melt(df, id_vars='SUBJID', value_vars=phenotype_cols,\n",
    "                           var_name='phenotype', value_name='observed')\n",
    "\n",
    "    # Remove unkonwns\n",
    "    unknown_values = ['none', 'unknown', 'no/not checked', 'not applicable', 'absent']\n",
    "    phenotype_df = phenotype_df[phenotype_df['observed'].apply(lambda x: x not in unknown_values)]\n",
    "\n",
    "    # Add HPOs\n",
    "    from dataservice.util.data_import.etl.hpo_mapper import mapper\n",
    "    phenotype_df = mapper.add_hpo_id_col(phenotype_df)\n",
    "\n",
    "    # Map to positive/negative\n",
    "    def func(row): \n",
    "        return 'negative' if row['observed'] == 'no' else 'positive'\n",
    "    phenotype_df['observed'] = phenotype_df.apply(func, axis=1)\n",
    "\n",
    "    # Merge back in age at event in days\n",
    "    phenotype_df = pd.merge(phenotype_df, age_at_event_days, on='SUBJID')\n",
    "\n",
    "    # Add unique col\n",
    "    def func(row): return \"_\".join(['phenotype', str(row.name)])\n",
    "    phenotype_df['phenotype_id'] = phenotype_df.apply(func, axis=1)\n",
    "    \n",
    "    # Write to file\n",
    "    phenotype_df.to_csv(hpo_fp, index=False)\n",
    "    \n",
    "    return phenotype_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjid</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>observed</th>\n",
       "      <th>hpo_id</th>\n",
       "      <th>latest_exam_age</th>\n",
       "      <th>phenotype_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21296</td>\n",
       "      <td>DYSMORPHIC_FACIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21296</td>\n",
       "      <td>HEAD_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21296</td>\n",
       "      <td>EYE_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21296</td>\n",
       "      <td>EAR_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21296</td>\n",
       "      <td>NOSE_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21296</td>\n",
       "      <td>NECK_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21296</td>\n",
       "      <td>MOUTH_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21296</td>\n",
       "      <td>PALATE_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21296</td>\n",
       "      <td>AIRWAY_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21296</td>\n",
       "      <td>CHEST_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21296</td>\n",
       "      <td>PULMONARY_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21296</td>\n",
       "      <td>HEPATIC_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21296</td>\n",
       "      <td>ABDOMINAL_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21296</td>\n",
       "      <td>RENAL_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21296</td>\n",
       "      <td>GENITOURINARY_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21296</td>\n",
       "      <td>GENERAL_SKELETAL_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21296</td>\n",
       "      <td>HAND_ABNORMALITIES_PRESENT</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21296</td>\n",
       "      <td>HAND_POLYDACTYLY</td>\n",
       "      <td>positive</td>\n",
       "      <td>HP:0001161</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21296</td>\n",
       "      <td>FEET_ABNORMALITIES_PRESENT</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21296</td>\n",
       "      <td>CLUB_FOOT</td>\n",
       "      <td>positive</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21296</td>\n",
       "      <td>NEUROLOGICAL_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21296</td>\n",
       "      <td>DERMATOLOGICAL_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21296</td>\n",
       "      <td>ENDOCRINOLOGIC_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>21296</td>\n",
       "      <td>THYMUS_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>21296</td>\n",
       "      <td>HEMATOLOGIC_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>21296</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21296</td>\n",
       "      <td>IMMUNOLOGIC_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9653</td>\n",
       "      <td>DYSMORPHIC_FACIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9653</td>\n",
       "      <td>HEAD_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9653</td>\n",
       "      <td>EYE_ABNORMALITIES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8306</th>\n",
       "      <td>27503</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8307</th>\n",
       "      <td>16227</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8308</th>\n",
       "      <td>6910</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>4380</td>\n",
       "      <td>phenotype_8308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8309</th>\n",
       "      <td>10209</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8310</th>\n",
       "      <td>7377</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>730</td>\n",
       "      <td>phenotype_8310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>24320</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>19689</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8313</th>\n",
       "      <td>18251</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>1095</td>\n",
       "      <td>phenotype_8313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8314</th>\n",
       "      <td>16165</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8315</th>\n",
       "      <td>20545</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>5475</td>\n",
       "      <td>phenotype_8315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8316</th>\n",
       "      <td>7809</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>5110</td>\n",
       "      <td>phenotype_8316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8317</th>\n",
       "      <td>8367</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>3285</td>\n",
       "      <td>phenotype_8317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8318</th>\n",
       "      <td>905</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8319</th>\n",
       "      <td>11939</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8320</th>\n",
       "      <td>8167</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>3285</td>\n",
       "      <td>phenotype_8320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8321</th>\n",
       "      <td>25692</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>6935</td>\n",
       "      <td>phenotype_8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8322</th>\n",
       "      <td>10342</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8323</th>\n",
       "      <td>6974</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>13505</td>\n",
       "      <td>phenotype_8323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8324</th>\n",
       "      <td>8363</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>1095</td>\n",
       "      <td>phenotype_8324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8325</th>\n",
       "      <td>7559</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>8760</td>\n",
       "      <td>phenotype_8325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8326</th>\n",
       "      <td>19151</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>4015</td>\n",
       "      <td>phenotype_8326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8327</th>\n",
       "      <td>2655</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>1460</td>\n",
       "      <td>phenotype_8327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>23618</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8329</th>\n",
       "      <td>8329</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>730</td>\n",
       "      <td>phenotype_8329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8330</th>\n",
       "      <td>14333</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>3650</td>\n",
       "      <td>phenotype_8330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8331</th>\n",
       "      <td>6591</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>2555</td>\n",
       "      <td>phenotype_8331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8332</th>\n",
       "      <td>5238</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>730</td>\n",
       "      <td>phenotype_8332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8333</th>\n",
       "      <td>20122</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>phenotype_8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8334</th>\n",
       "      <td>16457</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>1095</td>\n",
       "      <td>phenotype_8334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8335</th>\n",
       "      <td>7419</td>\n",
       "      <td>GENETIC_SYNDROMES_PRESENT</td>\n",
       "      <td>negative</td>\n",
       "      <td>None</td>\n",
       "      <td>730</td>\n",
       "      <td>phenotype_8335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8336 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     subjid                               phenotype  observed      hpo_id  \\\n",
       "0     21296               DYSMORPHIC_FACIES_PRESENT  negative        None   \n",
       "1     21296              HEAD_ABNORMALITIES_PRESENT  negative        None   \n",
       "2     21296               EYE_ABNORMALITIES_PRESENT  negative        None   \n",
       "3     21296               EAR_ABNORMALITIES_PRESENT  negative        None   \n",
       "4     21296              NOSE_ABNORMALITIES_PRESENT  negative        None   \n",
       "5     21296              NECK_ABNORMALITIES_PRESENT  negative        None   \n",
       "6     21296             MOUTH_ABNORMALITIES_PRESENT  negative        None   \n",
       "7     21296            PALATE_ABNORMALITIES_PRESENT  negative        None   \n",
       "8     21296            AIRWAY_ABNORMALITIES_PRESENT  negative        None   \n",
       "9     21296             CHEST_ABNORMALITIES_PRESENT  negative        None   \n",
       "10    21296         PULMONARY_ABNORMALITIES_PRESENT  negative        None   \n",
       "11    21296           HEPATIC_ABNORMALITIES_PRESENT  negative        None   \n",
       "12    21296         ABDOMINAL_ABNORMALITIES_PRESENT  negative        None   \n",
       "13    21296             RENAL_ABNORMALITIES_PRESENT  negative        None   \n",
       "14    21296     GENITOURINARY_ABNORMALITIES_PRESENT  negative        None   \n",
       "15    21296  GENERAL_SKELETAL_ABNORMALITIES_PRESENT  negative        None   \n",
       "16    21296              HAND_ABNORMALITIES_PRESENT  positive        None   \n",
       "17    21296                        HAND_POLYDACTYLY  positive  HP:0001161   \n",
       "18    21296              FEET_ABNORMALITIES_PRESENT  positive        None   \n",
       "19    21296                               CLUB_FOOT  positive        None   \n",
       "20    21296      NEUROLOGICAL_ABNORMALITIES_PRESENT  negative        None   \n",
       "21    21296    DERMATOLOGICAL_ABNORMALITIES_PRESENT  negative        None   \n",
       "22    21296    ENDOCRINOLOGIC_ABNORMALITIES_PRESENT  negative        None   \n",
       "23    21296            THYMUS_ABNORMALITIES_PRESENT  negative        None   \n",
       "24    21296       HEMATOLOGIC_ABNORMALITIES_PRESENT  negative        None   \n",
       "25    21296               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "26    21296       IMMUNOLOGIC_ABNORMALITIES_PRESENT  negative        None   \n",
       "27     9653               DYSMORPHIC_FACIES_PRESENT  negative        None   \n",
       "28     9653              HEAD_ABNORMALITIES_PRESENT  negative        None   \n",
       "29     9653               EYE_ABNORMALITIES_PRESENT  negative        None   \n",
       "...     ...                                     ...       ...         ...   \n",
       "8306  27503               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8307  16227               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8308   6910               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8309  10209               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8310   7377               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8311  24320               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8312  19689               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8313  18251               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8314  16165               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8315  20545               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8316   7809               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8317   8367               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8318    905               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8319  11939               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8320   8167               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8321  25692               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8322  10342               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8323   6974               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8324   8363               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8325   7559               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8326  19151               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8327   2655               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8328  23618               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8329   8329               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8330  14333               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8331   6591               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8332   5238               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8333  20122               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8334  16457               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "8335   7419               GENETIC_SYNDROMES_PRESENT  negative        None   \n",
       "\n",
       "      latest_exam_age    phenotype_id  \n",
       "0                   0     phenotype_0  \n",
       "1                   0     phenotype_1  \n",
       "2                   0     phenotype_2  \n",
       "3                   0     phenotype_3  \n",
       "4                   0     phenotype_4  \n",
       "5                   0     phenotype_5  \n",
       "6                   0     phenotype_6  \n",
       "7                   0     phenotype_7  \n",
       "8                   0     phenotype_8  \n",
       "9                   0     phenotype_9  \n",
       "10                  0    phenotype_10  \n",
       "11                  0    phenotype_11  \n",
       "12                  0    phenotype_12  \n",
       "13                  0    phenotype_13  \n",
       "14                  0    phenotype_14  \n",
       "15                  0    phenotype_15  \n",
       "16                  0    phenotype_16  \n",
       "17                  0    phenotype_17  \n",
       "18                  0    phenotype_18  \n",
       "19                  0    phenotype_19  \n",
       "20                  0    phenotype_20  \n",
       "21                  0    phenotype_21  \n",
       "22                  0    phenotype_22  \n",
       "23                  0    phenotype_23  \n",
       "24                  0    phenotype_24  \n",
       "25                  0    phenotype_25  \n",
       "26                  0    phenotype_26  \n",
       "27                  0    phenotype_27  \n",
       "28                  0    phenotype_28  \n",
       "29                  0    phenotype_29  \n",
       "...               ...             ...  \n",
       "8306                0  phenotype_8306  \n",
       "8307                0  phenotype_8307  \n",
       "8308             4380  phenotype_8308  \n",
       "8309                0  phenotype_8309  \n",
       "8310              730  phenotype_8310  \n",
       "8311                0  phenotype_8311  \n",
       "8312                0  phenotype_8312  \n",
       "8313             1095  phenotype_8313  \n",
       "8314                0  phenotype_8314  \n",
       "8315             5475  phenotype_8315  \n",
       "8316             5110  phenotype_8316  \n",
       "8317             3285  phenotype_8317  \n",
       "8318                0  phenotype_8318  \n",
       "8319                0  phenotype_8319  \n",
       "8320             3285  phenotype_8320  \n",
       "8321             6935  phenotype_8321  \n",
       "8322                0  phenotype_8322  \n",
       "8323            13505  phenotype_8323  \n",
       "8324             1095  phenotype_8324  \n",
       "8325             8760  phenotype_8325  \n",
       "8326             4015  phenotype_8326  \n",
       "8327             1460  phenotype_8327  \n",
       "8328                0  phenotype_8328  \n",
       "8329              730  phenotype_8329  \n",
       "8330             3650  phenotype_8330  \n",
       "8331             2555  phenotype_8331  \n",
       "8332              730  phenotype_8332  \n",
       "8333                0  phenotype_8333  \n",
       "8334             1095  phenotype_8334  \n",
       "8335              730  phenotype_8335  \n",
       "\n",
       "[8336 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_phenotype_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_gender_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read gender data for all subjects\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR,\n",
    "                                '3a_dbGaP_SubjectPhenotypes_GenderDS.txt')\n",
    "    df = pd.read_csv(filepath,\n",
    "                     delimiter='\\t',\n",
    "                     dtype={'SUBJID': str})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_demographic_data(filepaths=None):\n",
    "    \"\"\"\n",
    "    Read demographic data for all subjects (child, mother, father)\n",
    "    \"\"\"\n",
    "    if not filepaths:\n",
    "        filenames = ['3a_dbGaP_SubjectPhenotypes_DemographicsDS.txt',\n",
    "                     '3a_dbGaP_SubjectPhenotypes_MaternalDemographicsDS.txt',\n",
    "                     '3a_dbGaP_SubjectPhenotypes_PaternalDemographicsDS.txt']\n",
    "\n",
    "        filepaths = [os.path.join(DBGAP_DIR, filename)\n",
    "                     for filename in filenames\n",
    "                     ]\n",
    "\n",
    "    child_demo_df = pd.read_csv(os.path.join(filepaths[0]),\n",
    "                                delimiter='\\t',\n",
    "                                dtype={'SUBJID': str})\n",
    "\n",
    "    mother_demo_df = pd.read_csv(os.path.join(filepaths[1]),\n",
    "                                 delimiter='\\t',\n",
    "                                 dtype={'SUBJID': str})\n",
    "\n",
    "    father_demo_df = pd.read_csv(os.path.join(filepaths[2]),\n",
    "                                 delimiter='\\t',\n",
    "                                 dtype={'SUBJID': str})\n",
    "\n",
    "    # Combine demographics of all subjects\n",
    "    subject_demo_df = pd.concat(\n",
    "        [child_demo_df, mother_demo_df, father_demo_df])\n",
    "\n",
    "    subject_demo_df.drop_duplicates('SUBJID', inplace=True)\n",
    "    \n",
    "    # Subset of columns\n",
    "    subject_demo_df = subject_demo_df[['RACE', 'ETHNICITY', 'SUBJID']]\n",
    "\n",
    "    def func(row): return \"_\".join(['demographic', str(row.name)])\n",
    "    subject_demo_df['demographic_id'] = subject_demo_df.apply(func, axis=1)\n",
    "\n",
    "\n",
    "    return subject_demo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_diagnosis_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read diagnoses data for all subjects\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filename = '3a_dbGaP_SubjectPhenotypes_PatientDiagnosisDS.txt'\n",
    "        filepath = os.path.join(DBGAP_DIR, filename)\n",
    "\n",
    "    diagnosis_df = pd.read_csv(filepath,\n",
    "                               delimiter='\\t',\n",
    "                               dtype={'SUBJID': str})\n",
    "\n",
    "    def func(row): return \"_\".join(['diagnosis', str(row.name)])\n",
    "    diagnosis_df['diagnosis_id'] = diagnosis_df.apply(func, axis=1)\n",
    "\n",
    "    return diagnosis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_subject_sample_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read sample metadata for all subjects\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filename = '6a_dbGaP_SubjectSampleMappingDS.txt'\n",
    "        filepath = os.path.join(DBGAP_DIR, filename)\n",
    "\n",
    "    subject_sample_df = pd.read_csv(filepath,\n",
    "                                    delimiter='\\t',\n",
    "                                    dtype={'SUBJID': str})\n",
    "    subject_sample_df.drop_duplicates('SUBJID', inplace=True)\n",
    "\n",
    "    return subject_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliquot\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_sample_shipping_manifest_data(*filepaths):\n",
    "    \"\"\"\n",
    "    Read shipping manifest for samples (from PI/sample source center)\n",
    "    \"\"\"\n",
    "    if not filepaths:\n",
    "        filepaths = [os.path.join(ALIQUOT_SHIP_DIR, filename)\n",
    "\n",
    "                     for filename in os.listdir(ALIQUOT_SHIP_DIR)\n",
    "                     ]\n",
    "\n",
    "    # Combine all manifest files\n",
    "    dfs = [pd.read_excel(filepath,\n",
    "                         delimiter='/t',\n",
    "                         dtype={'*barcode': str},\n",
    "                         skiprows=[0, 1],\n",
    "                         header=[6])\n",
    "\n",
    "           for filepath in filepaths\n",
    "\n",
    "           if os.path.basename(filepath).startswith(\"PCGC\")\n",
    "\n",
    "           ]\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # Rename columns\n",
    "    df.columns = map((lambda x: x.lower().lstrip(\"*\")), df.columns)\n",
    "    \n",
    "    # Subset of columns\n",
    "    df = df[['barcode',\n",
    "             'external_id',\n",
    "             'sample_collection_site',\n",
    "             'sample_role',\n",
    "             'concentration_ng_per_ul',\n",
    "             'initial_volume_microliters']]\n",
    "\n",
    "    # Drop rows where id cols are nan\n",
    "    id_cols = [col for col in df.columns if \"id\" in col]\n",
    "    df.dropna(subset=id_cols, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing experiment (from read group metadata)\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_seq_experiment_data(filepath=None):\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR, \"seidman_metadata.xlsx\")\n",
    "\n",
    "    df = pd.read_excel(filepath, dtype={\"date\": str})\n",
    "    # Rename some columns\n",
    "    df.rename(columns={\"library_name (in original BAM header)\":\n",
    "                       \"library_name\",\n",
    "                       \"barcode\": \"rg_barcode\"}, inplace=True)\n",
    "    df[\"read_length\"] = df[\"read_length\"].apply(\n",
    "        lambda x: int(x.split(\"x\")[0]))\n",
    "    \n",
    "    # Create new columns\n",
    "    df['max_insert_size'] = df['insert_size'].max()\n",
    "    df['mean_insert_size'] = df['insert_size'].mean()\n",
    "    df['mean_read_length'] = df['read_length'].mean()\n",
    "    df['total_reads'] = df['read_length'].count()\n",
    "    \n",
    "    # Subset of columns\n",
    "    df = df[['sample_name',\n",
    "             'library_name',\n",
    "             'rg_barcode',\n",
    "             'run_name',\n",
    "             'read_length',\n",
    "             'date',\n",
    "             'library_strategy',\n",
    "             'library_source',\n",
    "             'library_selection',\n",
    "             'insert_size',\n",
    "             'instrument',\n",
    "             'library_layout',\n",
    "             'max_insert_size',\n",
    "             'mean_insert_size',\n",
    "             'mean_read_length',\n",
    "             'total_reads']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction - Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_files_df = read_study_file_data()\n",
    "study_files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family \n",
    "family_df = read_family_data()\n",
    "family_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenotypes\n",
    "phenotype_df = read_phenotype_data()\n",
    "phenotype_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "gender_df = read_gender_data()\n",
    "gender_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic\n",
    "demographic_df = read_demographic_data()\n",
    "demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis data\n",
    "diagnosis_df = read_diagnosis_data()\n",
    "diagnosis_df.head()\n",
    "# diagnosis_df[diagnosis_df['subjid'] == '279']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "subject_sample_df = read_subject_sample_data()\n",
    "subject_sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aliquot/Sample Shipping data\n",
    "shipping_manifest_df = read_sample_shipping_manifest_data()\n",
    "shipping_manifest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing experiments\n",
    "seq_exp_df = read_seq_experiment_data()\n",
    "seq_exp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants\n",
    "print(\"Family\")\n",
    "print(family_df.nunique())\n",
    "print(\"\\nDemographics\")\n",
    "print(demographic_df.nunique())\n",
    "print(\"\\nGender\")\n",
    "print(demographic_df.nunique())\n",
    "print(\"\\nDiagnosis\")\n",
    "print(demographic_df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigator\n",
    "investigator_df = read_investigator_data()\n",
    "investigator_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study\n",
    "study_df = read_study_data()\n",
    "study_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study files\n",
    "study_files_df = read_study_file_data()\n",
    "study_files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "family_df = read_family_data()\n",
    "family_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create participant df\n",
    "# Merge Gender + Demographics\n",
    "gender_demo_df = pd.merge(gender_df, demographic_df, on='subjid')\n",
    "# Add Family\n",
    "df1 = pd.merge(gender_demo_df, family_df, on='subjid')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Diagnosis\n",
    "df2 = pd.merge(df1, diagnosis_df, on='subjid')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge Sample\n",
    "df3 = pd.merge(df2, subject_sample_df, on='subjid')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge Aliquot\n",
    "df4 = pd.merge(df3, shipping_manifest_df, left_on='sampid', right_on='external_id')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Sequencing Experiment\n",
    "full_participant_df = pd.merge(df4, seq_exp_df, left_on='external_id', right_on='sample_name')\n",
    "full_participant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create study\n",
    "study = {\n",
    "    'data_access_authority': 'dbGaP',\n",
    "    'study_id': 'phs001138',\n",
    "    'study_version': 'v1.p2',\n",
    "    'study_name': 'Discovery of the Genetic Basis of Structural Heart'\n",
    "    'and Other Birth Defects',\n",
    "    'attribution': 'https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/'\n",
    "    'GetAcknowledgementStatement.cgi?study_id=phs001138.v1.p2'\n",
    "}\n",
    "study_df = pd.DataFrame([study])\n",
    "study_df.to_csv(os.path.join(DATA_DIR, 'study.txt'))\n",
    "\n",
    "# Create investigator\n",
    "invest = {\n",
    "    'investigator_name': 'Christine E. Seidman',\n",
    "    'institution': 'Harvard Medical School'\n",
    "}\n",
    "inv_df = pd.DataFrame([invest])\n",
    "inv_df.to_csv(os.path.join(DATA_DIR, 'investigator.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_study_cols(study_df, df):\n",
    "    # Add study cols to a df\n",
    "    cols = study_df.columns.tolist()\n",
    "    row = study_df.iloc[0]\n",
    "    for col in cols:\n",
    "        df[col] = row[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add study to full participant df\n",
    "_add_study_cols(study_df, full_participant_df)\n",
    "\n",
    "# Add study to basic participant df\n",
    "participant_df = _add_study_cols(study_df, family_df)\n",
    "\n",
    "# Add study to investigator df\n",
    "study_investigator_df =_add_study_cols(study_df, investigator_df)\n",
    "\n",
    "# Add study to study files df\n",
    "study_study_files_df = _add_study_cols(study_df, study_files_df)\n",
    "\n",
    "# Phenotype df\n",
    "phenotype_participant_df = pd.merge(phenotype_df, participant_df,\n",
    "                                    on='subjid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "n = 22\n",
    "chunk_size = 10\n",
    "entity_type ='participant'\n",
    "entities = ['{}_{}'.format(entity_type, j) for j in range(n)]\n",
    "for i in range(0, n, chunk_size):\n",
    "    chunk = entities[i - chunk_size:i]\n",
    "    if chunk:\n",
    "        start = i - chunk_size + 1\n",
    "        print('Adding {}:{} {}s to session'.format(start, i,\n",
    "                                                   entity_type))\n",
    "        pprint([e for e in entities[start:i]])\n",
    "        print('Flushing {} {}\\ns'.format(chunk_size, entity_type))\n",
    "\n",
    "print('Flushing remaining {} {}s to session\\n'.format(\n",
    "    len(entities[i:]) + 1, entity_type))\n",
    "\n",
    "remaining = entities[0:1] + entities[i:]\n",
    "\n",
    "pprint([e for e in remaining])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def read_json(filepath):\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        return json.load(json_file)\n",
    "\n",
    "\n",
    "def write_json(data, filepath):\n",
    "    with open(filepath, 'w') as json_file:\n",
    "        json.dump(data, json_file, sort_keys=True, indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join(DATA_DIR, 'genomic_file_uuid.json')\n",
    "file_json = read_json(fp)\n",
    "write_json(file_json, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genomic file info df\n",
    "def read_genomic_file_info(filepath=None):\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR, 'genomic_file_uuid.json')\n",
    "        \n",
    "    def get_ext(fp):\n",
    "        filename = os.path.basename(fp)\n",
    "        parts = filename.split('.')\n",
    "        if len(parts) > 2:\n",
    "            ext = '.'.join(parts[1:])\n",
    "        else:\n",
    "            ext = parts[-1]\n",
    "        return ext\n",
    "\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        uuid_dict = json.load(json_file)\n",
    "\n",
    "    gf_dicts = []\n",
    "    for k, v in uuid_dict.items():\n",
    "        file_info = {\n",
    "            'uuid': v['did'],\n",
    "            'md5sum': v['hashes']['md5'],\n",
    "            'file_url': v['urls'][0],\n",
    "            'file_size': v['size'],\n",
    "            'data_type': 'submitted aligned reads',\n",
    "            'file_format': get_ext(v['urls'][0]),\n",
    "            'file_name': os.path.basename(v['urls'][0])\n",
    "        }\n",
    "        gf_dicts.append(file_info)\n",
    "        \n",
    "    return pd.DataFrame(gf_dicts)\n",
    "\n",
    "def read_sample_gf_data(filepath=None):\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR, 'manifests', 'GMKF_BAMsampleIDs.xlsx')\n",
    "    df = pd.read_excel(filepath)\n",
    "    df = df.loc[df['Cohort'] == 'GMKF-Seidman']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read genomic file info\n",
    "gf_file_info_df = read_genomic_file_info()\n",
    "# Sample and BAM File df\n",
    "sample_gf_df = read_sample_gf_data()\n",
    "# Merge with sequencing experiment df\n",
    "df1 = pd.merge(sample_gf_df, seq_exp_df, left_on='dbgap_subject_id', right_on='sample_name')\n",
    "# Merge with genomic file info df\n",
    "df2 = pd.merge(df1, gf_file_info_df, left_on='BAM sample ID', right_on='file_name')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_genomic_file_info()\n",
    "print(df['file_size'].max()/1000000000)\n",
    "print(df['file_size'].min()/1000000000)\n",
    "print(df['file_size'].mean()/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_phenotype_data()\n",
    "df['observed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/singhn4/Desktop/phenotype.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.where((pd.notnull(df)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
