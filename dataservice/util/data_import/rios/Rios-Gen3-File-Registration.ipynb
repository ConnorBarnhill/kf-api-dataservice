{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JSON documents for submission to Gen3 indexd\n",
    "\n",
    "This notebook will create documents for files listed in the s3 bucket `kf-seq-data-hudsonalpha` for the Rios_Wise_2016 cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "import boto3\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "DATA_DIR = '/Users/singhn4/Projects/kids_first/data/Rios_Wise_2016/'\n",
    "GF_DIR = os.path.join(DATA_DIR, 'genomic_files')\n",
    "GF_BY_UUID_FP = os.path.join(DATA_DIR, 'genomic_files_by_uuid.json')\n",
    "STUDY_ID = 'phs001410'\n",
    "BUCKET_NAME = 'kf-seq-data-hudsonalpha'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def read_json(filepath):\n",
    "    with open(filepath, 'r') as json_file:\n",
    "        return json.load(json_file)\n",
    "    \n",
    "def write_json(data, filepath):\n",
    "    with open(filepath, 'w') as json_file:\n",
    "        json.dump(data, json_file, sort_keys=True, indent=4, separators=(',', ':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(395, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Rios genomic file manifest into dict\n",
    "filepath = os.path.join(DATA_DIR, 'manifests', 'manifest_171210.csv')\n",
    "df = pd.read_csv(filepath)\n",
    "df['Sample Description'] = df['Sample Description'].apply(\n",
    "    lambda x: x.split(':')[-1].strip())\n",
    "df.set_index('Library', inplace=True)\n",
    "gf_manifest_dict = df.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all HudsonAlpha objects\n",
    "by_uuid = {}\n",
    "bucket = client.Bucket(BUCKET_NAME)\n",
    "# For all objects in hudsonalpha bucket\n",
    "for obj in bucket.objects.all():\n",
    "    if obj.key.startswith('hai'):\n",
    "        # Check if this file exists in the manifest\n",
    "        if obj.key.split('/')[-2] not in gf_manifest_dict:\n",
    "            print('{} has no matching entry in manifest'.format(obj.key))\n",
    "            continue\n",
    "\n",
    "        # Create file registration\n",
    "        md5 = obj.e_tag.split('-')[0].strip('\\\"')\n",
    "        size = obj.size\n",
    "        file_name = os.path.basename(obj.key)\n",
    "        path = 's3://{}/{}'.format(BUCKET_NAME, obj.key)\n",
    "        _id = str(uuid.uuid4())\n",
    "        body = {\n",
    "            'metadata': {'acls': STUDY_ID},\n",
    "            'did': _id,\n",
    "            'file_name': file_name,\n",
    "            'form': 'object',\n",
    "            'size': size,\n",
    "            'urls': [path],\n",
    "            'hashes': {\n",
    "                'md5': md5\n",
    "            }\n",
    "        }\n",
    "        by_uuid[_id] = body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "if not os.path.exists(GF_BY_UUID_FP):\n",
    "    write_json(by_uuid, GF_BY_UUID_FP)\n",
    "else:\n",
    "    print('{} already exists'.format(GF_BY_UUID_FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read uuid file\n",
    "data = read_json(GF_BY_UUID_FP)\n",
    "df = pd.DataFrame(list(data.values()))\n",
    "urls = {val['urls'][0] for val in data.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit files to Gen3 QA via indexd endpoint\n",
    "# Get auth \n",
    "ENABLE=False\n",
    "if ENABLE:\n",
    "    auth = (os.environ.get('KF_INDEXD_UNAME'), os.environ.get('KF_INDEXD_PWD'))\n",
    "    for k, body in data.items():\n",
    "            resp = requests.post('https://gen3qa.kids-first.io/index/index/',\n",
    "                                 auth=auth,\n",
    "                                 json=body)\n",
    "            print(resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve lost uuids :(\n",
    "_id_stack = list(urls)\n",
    "auth = (os.environ.get('KF_INDEXD_UNAME'), os.environ.get('KF_INDEXD_PWD'))\n",
    "API_URL = 'https://gen3qa.kids-first.io/index/index'\n",
    "\n",
    "# Get first id\n",
    "r = requests.get(API_URL)\n",
    "current_id = r.json()['ids'][0]\n",
    "payloads = []\n",
    "count = 0\n",
    "while _id_stack or current_id:\n",
    "    # Get a page\n",
    "    print('Page {}'.format(count))\n",
    "    endpoint = API_URL + '/?start=' + str(current_id)\n",
    "    print('Get {}'.format(endpoint))\n",
    "    r = requests.get(endpoint, auth=auth)\n",
    "    _ids = r.json()['ids']\n",
    "    # For each id in page, get payload and save it\n",
    "    for i, _id in enumerate(_ids):\n",
    "        print('\\tId #{} = {}'.format(i,_id))\n",
    "        r1 = requests.get(API_URL + '/' + _id)\n",
    "        b = r1.json()\n",
    "        url_key = b['urls'][0]\n",
    "        # If this is a url we're looking for, pop it off the stack\n",
    "        if url_key in urls and _id_stack:\n",
    "            print('\\t\\tFound a url {}'.format(url_key))\n",
    "            _id_stack.pop()\n",
    "        else:\n",
    "            print('Url {}'.format(url_key))\n",
    "        payloads.append(b)\n",
    "    # Set next page\n",
    "    if _ids:\n",
    "        current_id = _ids[-1]\n",
    "    else:\n",
    "        current_id = None\n",
    "    count+=1\n",
    "    print('Payload total {}'.format(len(payloads)))\n",
    "    print('Id Stack total {}'.format(len(_id_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "print('Complete!')\n",
    "if payloads:\n",
    "    write_json(payloads, os.path.join(DATA_DIR, 'payloads.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "in_payloads = read_json(os.path.join(DATA_DIR, 'payloads.json'))\n",
    "df = pd.DataFrame(in_payloads)\n",
    "def func(row):\n",
    "    if 'acls' in row['metadata']:\n",
    "        return row['metadata']['acls'].strip()\n",
    "    else:\n",
    "        return None\n",
    "df['study_id'] = df.apply(func, axis=1)\n",
    "df = df[df['study_id'] == 'phs001410']\n",
    "df['s3_path'] = df['urls'].apply(lambda x: x[0])\n",
    "df = df[['did', 's3_path']]\n",
    "\n",
    "# Originals\n",
    "orig = read_json(GF_BY_UUID_FP)\n",
    "df0 = pd.DataFrame(list(orig.values()))\n",
    "df0['s3_path'] = df0['urls'].apply(lambda x: x[0])\n",
    "del df0['did']\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.merge(df, df0, on='s3_path')\n",
    "del merged_df['s3_path']\n",
    "merged_df['_index'] = merged_df['did']\n",
    "merged_df.set_index('_index', inplace=True)\n",
    "results = merged_df.to_dict(orient='index')\n",
    "\n",
    "# Write to file\n",
    "verified_gf_fp = os.path.join(DATA_DIR, 'verified_genomic_files_by_uuid.json')\n",
    "write_json(results, verified_gf_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
