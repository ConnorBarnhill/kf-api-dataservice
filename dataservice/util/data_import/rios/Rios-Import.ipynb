{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from dataservice.util.data_import.utils import (\n",
    "    dropna_rows_cols,\n",
    "    reformat_column_names,\n",
    "    cols_to_lower,\n",
    "    read_json, \n",
    "    write_json,\n",
    "    extract_uncompressed_file_ext\n",
    ")\n",
    "\n",
    "DATA_DIR = '/Users/singhn4/Projects/kids_first/data/Rios_Wise_2016'\n",
    "DBGAP_DIR = os.path.join(DATA_DIR, 'dbgap')\n",
    "MANIFESTS_DIR = os.path.join(DATA_DIR, 'manifests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create study\n",
    "study = {\n",
    "    'data_access_authority': 'dbGaP',\n",
    "    'study_id': 'phs001410',\n",
    "    'study_version': 'v1.p2',\n",
    "    'study_name': 'Genomics of Orthopaedic Disease Program',\n",
    "    'attribution': None\n",
    "}\n",
    "study_df = pd.DataFrame([study])\n",
    "study_df.to_csv(os.path.join(DATA_DIR, 'study.txt'), index=False)\n",
    "\n",
    "# Create investigator\n",
    "invest = {\n",
    "    'investigator_name': 'Jonathan Rios',\n",
    "    'institution': 'UT Southwestern Medical Center'\n",
    "}\n",
    "inv_df = pd.DataFrame([invest])\n",
    "inv_df.to_csv(os.path.join(DATA_DIR, 'investigator.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_study_file_data(filepaths=None):\n",
    "    \"\"\"\n",
    "    Read in raw study files\n",
    "    \"\"\"\n",
    "    if not filepaths:\n",
    "        filepaths = os.listdir(DBGAP_DIR)\n",
    "\n",
    "    study_files = [{\"study_file_name\": f}\n",
    "                   for f in filepaths if 'dbGaP' in f]\n",
    "    return pd.DataFrame(study_files)\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_study_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read study data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR,\n",
    "                                'study.txt')\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_investigator_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read investigator data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR,\n",
    "                                'investigator.txt')\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_subject_data(filepath=None):\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, 'HL13237501A1_V3_SubjectDS.txt')\n",
    "    df = pd.read_csv(filepath, delimiter='\\t', dtype={'SUBJID': str})\n",
    "    df = df[['SUBJECT_ID', 'CONSENT']]\n",
    "    \n",
    "    # Decode consent ints to consent strings\n",
    "    def func(row): \n",
    "        _map = {0:None, \n",
    "                1: \"Health/Medical/Biomedical (IRB)\", \n",
    "                2: \"Disease-Specific (Musculoskeletal Diseases, IRB)(DS-MUS-SKEL-IRB)\"}\n",
    "        return _map[row['CONSENT']]\n",
    "    df['CONSENT'] = df.apply(func, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_phenotype_data(filepath=None):\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, 'HL132375-01A1_V2_SubjectPhenotypesDS.txt')\n",
    "    df = pd.read_csv(filepath, \n",
    "                    delimiter='\\t', \n",
    "                    dtype={'SUBJID': str})\n",
    "    \n",
    "    # Decode sex ints to gender strings\n",
    "    def func(row): \n",
    "        _map = {1: \"male\", 2: \"female\"}\n",
    "        return _map[row['Sex']]\n",
    "    df['Sex'] = df.apply(func, axis=1)\n",
    "\n",
    "    # Decode affected status ints to strings\n",
    "    def func(row): \n",
    "        _map = {0:'unknown', 1: \"not affected\", 2: \"affected\"}\n",
    "        return _map[row['AFFSTAT']]\n",
    "    df['AFFSTAT'] = df.apply(func, axis=1)\n",
    "\n",
    "    # Decode proband ints to booleans\n",
    "    def func(row): \n",
    "        _map = {1: True, 2: False}\n",
    "        return _map[row['Proband']]\n",
    "    df['Proband'] = df.apply(func, axis=1)\n",
    "    \n",
    "    # Create ethnicity column\n",
    "    _map = {'Hispanic': 'hispanic or latino'}\n",
    "    df['ethnicity'] = df['Race'].apply(lambda x: _map.get(x, 'not hispanic or latino'))\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_family_data(filepath=None):\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, 'HL132375-01A1_V2_PedgreeDS.txt')\n",
    "    df = pd.read_csv(filepath, delimiter='\\t', dtype={'SUBJID': str})\n",
    "    del df['SEX']\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def create_participant_data():\n",
    "    \"\"\"\n",
    "    Create participant data from \n",
    "    \"\"\"\n",
    "    # Subject file\n",
    "    subject_df = read_subject_data()\n",
    "    # Phenotype file\n",
    "    phenotypes_df = read_phenotype_data()\n",
    "    # Family file\n",
    "    family_df = read_family_data()\n",
    "    \n",
    "    # Merge subject + phenotype\n",
    "    df1 = pd.merge(subject_df, phenotypes_df, on='subject_id')\n",
    "    \n",
    "    # Merge family\n",
    "    df = pd.merge(df1, family_df, on='subject_id')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_diagnosis_df(phenotype_df):\n",
    "    \"\"\"\n",
    "    Create diagnosis df from phenotype df\n",
    "    \"\"\"\n",
    "    def func(row): \n",
    "        _map = {'affected':'adolescent idiopathic scoliosis', \n",
    "                'not affected': None}\n",
    "        return _map.get(row['affstat'], row['affstat'])\n",
    "    phenotype_df['diagnosis'] = phenotype_df.apply(func, axis=1)\n",
    "    \n",
    "    return phenotype_df[['subject_id', 'diagnosis']]\n",
    "\n",
    "def create_phenotype_df(phenotype_df):\n",
    "    \"\"\"\n",
    "    Create phenotype df from original phenotype_df\n",
    "    \"\"\"\n",
    "    # Extract columns\n",
    "    phenotype_df = phenotype_df[['subject_id', 'affstat']]\n",
    "    # Drop unknowns\n",
    "    phenotype_df = phenotype_df[phenotype_df.affstat != 'unknown']\n",
    "    \n",
    "    # Add columns\n",
    "    def func(row): \n",
    "        _map = {'affected':'positive', \n",
    "                'not affected': 'negative'}\n",
    "        return _map.get(row['affstat'], row['affstat'])\n",
    "    \n",
    "    phenotype_df['observed'] = phenotype_df.apply(func, axis=1)\n",
    "    phenotype_df['hpo_id'] = 'HP:0002650'\n",
    "    phenotype_df['phenotype'] = 'adolescent idiopathic scoliosis'\n",
    "    return phenotype_df\n",
    "df = create_diagnosis_df(read_phenotype_data())\n",
    "df.diagnosis.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_sample_attr_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read sample attributes file\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, 'HL132375-01A1_V2_SampleAttributesDS.txt')\n",
    "    return pd.read_csv(filepath, delimiter='\\t')\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_subject_sample_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read subject sample mapping file\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, 'HL132375-01A1_V2_SubjectSampleMappingDS.txt')\n",
    "    return pd.read_csv(filepath, delimiter='\\t')\n",
    "\n",
    "# Sample attributes file\n",
    "sample_attr_df = read_sample_attr_data()\n",
    "sample_attr_df.shape\n",
    "# Subject sample file\n",
    "subject_sample_df = read_subject_sample_data()\n",
    "# Subject file\n",
    "subject_df = read_subject_data()\n",
    "\n",
    "# Merge sample attributes w subject sample\n",
    "df1 = pd.merge(sample_attr_df, subject_sample_df, on='sample_id')\n",
    "# Merge sample with subject\n",
    "sample_df = pd.merge(df1, subject_df, on='subject_id')\n",
    "sample_df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_seq_exp_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read sequencing experiment data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(MANIFESTS_DIR, 'manifest_171210.csv')\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['Sample Description'] = df['Sample Description'].apply(lambda x: x.split(':')[-1].strip())\n",
    "\n",
    "    # Add unique col\n",
    "    def func(row): return \"_\".join(['seq_exp', str(row.name)])\n",
    "    df['seq_exp_id'] = df.apply(func, axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def create_biospecimen_data(participant_df):\n",
    "    \"\"\"\n",
    "    Create biospeciment df\n",
    "    \"\"\"\n",
    "    # Sample attributes file\n",
    "    sample_attr_df = read_sample_attr_data()\n",
    "    # Subject sample file\n",
    "    subject_sample_df = read_subject_sample_data()\n",
    "    # Merge sample attributes w subject sample\n",
    "    df1 = pd.merge(subject_sample_df, sample_attr_df, how='left', on='sample_id')\n",
    "    # Merge sample with participant_df\n",
    "    biospecimen_df = pd.merge(df1, participant_df[['subject_id', 'sex']], on='subject_id')\n",
    "\n",
    "    return biospecimen_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_genomic_files_info(filepath):\n",
    "    \"\"\"\n",
    "    Read genomic file info json produced by Gen3 registration\n",
    "    and convert into genomic file table for dataservice\n",
    "    \"\"\"\n",
    "    data = read_json(filepath)\n",
    "    df = pd.DataFrame(list(data.values()))\n",
    "\n",
    "    # Reformat\n",
    "    df['md5sum'] = df['hashes'].apply(lambda x: x['md5'])\n",
    "    df['file_url'] = df['urls'].apply(lambda x: x[0])\n",
    "    df['file_name'] = df['file_url'].apply(\n",
    "        lambda file_url: os.path.basename(file_url))\n",
    "    df['file_format'] = df['file_name'].apply(\n",
    "        extract_uncompressed_file_ext)\n",
    "    df.rename(columns={'did': 'uuid', 'size': 'file_size'}, inplace=True)\n",
    "\n",
    "    # Data type\n",
    "    def func(x):\n",
    "        x = x.strip()\n",
    "        if x.endswith('cram') or x.endswith('bam'):\n",
    "            val = 'submitted aligned reads'\n",
    "        elif x.endswith('crai'):\n",
    "            val = 'submitted aligned reads index'\n",
    "        elif 'fastq' in x:\n",
    "            val = 'submitted reads'\n",
    "        elif 'vcf' in x:\n",
    "            val = 'simple nucleotide variation'\n",
    "        else:\n",
    "            val = None\n",
    "        return val\n",
    "\n",
    "    df['data_type'] = df['file_name'].apply(func)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Db gap files\n",
    "files = {f:os.path.join(DBGAP_DIR, f) for f in os.listdir(DBGAP_DIR)}\n",
    "pprint(list(files.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(files['HL13237501A1_V3_SubjectDS.txt'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject \n",
    "df2 = pd.read_csv(files['HL132375-01A1_V2_SubjectDS.txt'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.merge(df1, df2, on='SUBJECT_ID')\n",
    "df3.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family/Pedigree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files['HL132375-01A1_V2_PedgreeDS.txt'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files['HL132375-01A1_V2_SubjectPhenotypesDS.txt'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample attributes\n",
    "filepath = os.path.join(DBGAP_DIR, 'HL132375-01A1_V2_SampleAttributesDS.txt')\n",
    "df = pd.read_csv(filepath, delimiter='\\t')\n",
    "cols_to_lower(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.histological_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject sample mapping\n",
    "filepath = os.path.join(DBGAP_DIR, 'HL132375-01A1_V2_SubjectSampleMappingDS.txt')\n",
    "df = pd.read_csv(filepath, delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant + Demographic df\n",
    "participant_df = create_participant_data()\n",
    "participant_df.head()\n",
    "participant_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Families and Proband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('# of families {}'.format(participant_df['family_id'].nunique()))\n",
    "print('# of probands {}'.format(participant_df[participant_df['proband'] == True]['proband'].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Families without a Proband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = participant_df.groupby(['family_id'])[['subject_id', 'affstat', 'proband', 'family_id']]\n",
    "p = g.describe()['proband']\n",
    "p[p['unique'] != 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participants Affected but NOT a Proband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = participant_df[(participant_df['affstat'] == 'affected') & (participant_df['proband'] == False)]['subject_id'].nunique()\n",
    "print('# of affected participants that are not probands {} '.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family df\n",
    "family_df = read_family_data()\n",
    "mothers = pd.merge(family_df[['subject_id', 'family_id']], family_df[['mother', 'father']], left_on='subject_id', right_on='mother')\n",
    "mothers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fathers = pd.merge(family_df[['subject_id', 'family_id']], family_df[['mother', 'father']], left_on='subject_id', right_on='father')\n",
    "fathers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenotype df\n",
    "phenotype_df = read_phenotype_data()\n",
    "phenotype_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnosis\n",
    "diagnosis_df = create_diagnosis_df(phenotype_df)\n",
    "diagnosis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing Experiments\n",
    "seq_exp_df = read_seq_exp_data()\n",
    "print(seq_exp_df.nunique())\n",
    "seq_exp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biospecimen_df = create_biospecimen_data(participant_df)\n",
    "print(biospecimen_df.nunique())\n",
    "biospecimen_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def create_genomic_file_df(seq_exp_df, biospecimen_df):\n",
    "    \"\"\"\n",
    "    Create genomic file df\n",
    "    \"\"\"\n",
    "    # Genomic file info\n",
    "    filepath = os.path.join(DATA_DIR, 'genomic_files_by_uuid.json')\n",
    "    gf_df = read_genomic_files_info(filepath)\n",
    "    # Add library\n",
    "    gf_df['library'] = gf_df['file_url'].apply(\n",
    "        lambda file_url: os.path.dirname(file_url).split('/')[-1])\n",
    "\n",
    "    # Merge sequencing experiments\n",
    "    df1 = pd.merge(seq_exp_df, gf_df, on='library')\n",
    "    \n",
    "    # Merge biospecimens\n",
    "    genomic_file_df = pd.merge(biospecimen_df, df1, left_on='sample_id', right_on='sample_description')\n",
    "\n",
    "    return genomic_file_df\n",
    "genomic_file_df = create_genomic_file_df(seq_exp_df, biospecimen_df)\n",
    "# genomic_file_df.describe(include='O')\n",
    "genomic_file_df[['sample_id', 'library', 'file_name']].describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
