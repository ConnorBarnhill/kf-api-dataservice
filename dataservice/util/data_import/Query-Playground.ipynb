{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from importlib import import_module\n",
    "\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from sqlalchemy.orm import joinedload, subqueryload, Load, load_only\n",
    "from sqlalchemy.orm.exc import NoResultFound\n",
    "from sqlalchemy.dialects import postgresql\n",
    "\n",
    "from dataservice.extensions import db\n",
    "from dataservice.utils import iterate_pairwise\n",
    "from dataservice import create_app\n",
    "from dataservice.api.investigator.models import Investigator\n",
    "from dataservice.api.study.models import Study\n",
    "from dataservice.api.participant.models import Participant\n",
    "from dataservice.api.biospecimen.models import Biospecimen\n",
    "from dataservice.api.family.models import Family\n",
    "from dataservice.api.family_relationship.models import FamilyRelationship\n",
    "from dataservice.api.diagnosis.models import Diagnosis\n",
    "from dataservice.api.outcome.models import Outcome\n",
    "from dataservice.api.phenotype.models import Phenotype\n",
    "from dataservice.api.genomic_file.models import GenomicFile\n",
    "from dataservice.api.sequencing_experiment.models import SequencingExperiment\n",
    "from dataservice.api.workflow.models import Workflow, WorkflowGenomicFile\n",
    "from dataservice.api.study_file.models import StudyFile\n",
    "\n",
    "from dataservice.util.data_import.utils import to_camel_case\n",
    "from dataservice.util.data_import.etl.defaults import DEFAULT_ENTITY_TYPES\n",
    "\n",
    "study_id = 'SD_SJZFK2VV'\n",
    "\n",
    "class BaseLoader(object):\n",
    "\n",
    "    def __init__(self, config_name=None):\n",
    "        if not config_name:\n",
    "            config_name = 'development'\n",
    "        self.setup(config_name)\n",
    "        self.entity_id_map = {}\n",
    "\n",
    "    def setup(self, config_name):\n",
    "        \"\"\"\n",
    "        Creates tables in database\n",
    "        \"\"\"\n",
    "        self.app = create_app(config_name)\n",
    "        self.app.config['SQLALCHEMY_ECHO'] = True\n",
    "        self.app_context = self.app.app_context()\n",
    "        self.app_context.push()\n",
    "#         db.create_all()\n",
    "\n",
    "    def teardown(self):\n",
    "        \"\"\"\n",
    "        Clean up\n",
    "        \"\"\"\n",
    "        db.session.close()\n",
    "        db.drop_all()\n",
    "\n",
    "    def drop_all(self, study_external_id):\n",
    "        \"\"\"\n",
    "        Delete all data related to a study\n",
    "        \"\"\"\n",
    "        from dataservice.api.study.models import Study\n",
    "        from dataservice.api.investigator.models import Investigator\n",
    "\n",
    "        try:\n",
    "            study = Study.query.filter_by(external_id=study_external_id).one()\n",
    "        except NoResultFound:\n",
    "            print(\"Study {} not found. Aborting drop all for this dataset\"\n",
    "                  .format(study_external_id))\n",
    "        else:\n",
    "            # Save investigator id\n",
    "            investigator_id = study.investigator_id\n",
    "\n",
    "            # Delete study\n",
    "            db.session.delete(study)\n",
    "\n",
    "            # Delete investigator\n",
    "            if investigator_id:\n",
    "                investigator = Investigator.query.get(investigator_id)\n",
    "                db.session.delete(investigator)\n",
    "\n",
    "            db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = BaseLoader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Entities by Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants\n",
    "q = (Participant.query\n",
    "                .options(joinedload(Participant.diagnoses)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.biospecimens)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.phenotypes)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.outcomes)\n",
    "                        .load_only('kf_id')))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Family \n",
    "q = (Family.query\n",
    "     .options(load_only('kf_id'))\n",
    "     .join(Family.participants)\n",
    "     .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "     .filter(Participant.study_id==study_id)\n",
    "     .distinct(Family.kf_id)\n",
    "     .order_by(Family.kf_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family relationship\n",
    "q = (FamilyRelationship.query\n",
    "     .options(load_only('kf_id'))\n",
    "     .join(FamilyRelationship.participant)\n",
    "    .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "    .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Study File\n",
    "q = (StudyFile.query\n",
    "     .options(load_only('kf_id'))\n",
    "     .filter(StudyFile.study_id == study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigator\n",
    "q = (Investigator.query\n",
    "     .options(load_only('kf_id'))\n",
    "     .join(Investigator.studies)\n",
    "     .options(Load(Study).load_only('kf_id'))\n",
    "     .filter(Study.kf_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Genomic files\n",
    "q = (GenomicFile.query\n",
    "     .options(load_only('kf_id'))\n",
    "     .join(GenomicFile.biospecimen)\n",
    "     .join(Biospecimen.participant)\n",
    "     .options(Load(Participant).load_only(\"kf_id\", \"study_id\"))\n",
    "     .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biospecimen\n",
    "q = (Biospecimen.query\n",
    "     .options(load_only('kf_id'))\n",
    "     .join(Participant.biospecimens)\n",
    "     .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "     .filter(Participant.study_id == study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing experiment\n",
    "q = (SequencingExperiment.query\n",
    "     .options(load_only('kf_id'))\n",
    "     .join(SequencingExperiment.genomic_files)\n",
    "     .join(GenomicFile.biospecimen)\n",
    "     .join(Biospecimen.participant)\n",
    "     .options(Load(Participant).load_only(\"kf_id\", \"study_id\"))\n",
    "     .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = create_app('testing')\n",
    "app_context = app.app_context()\n",
    "app_context.push()\n",
    "db.drop_all()\n",
    "db.create_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a bunch of studies for pagination\n",
    "s = Study(external_id='Study_1'.format(i))\n",
    "db.session.add(s)\n",
    "db.session.commit()\n",
    "\n",
    "data = {\n",
    "    'external_id': \"test\",\n",
    "    'is_proband': True,\n",
    "    'consent_type': 'GRU-IRB',\n",
    "    'race': 'asian',\n",
    "    'ethnicity': 'not hispanic',\n",
    "    'gender': 'male'\n",
    "}\n",
    "\n",
    "p = Participant(**data, study_id=s.kf_id)\n",
    "samp = Biospecimen(analyte_type='an analyte')\n",
    "se_kwargs = {\n",
    "    'external_id': 'se1',\n",
    "    'experiment_strategy': 'WGS',\n",
    "    'center': 'Baylor',\n",
    "    'is_paired_end': True,\n",
    "    'platform': 'Illumina'\n",
    "}\n",
    "seq_exp = SequencingExperiment(**se_kwargs)\n",
    "gf = GenomicFile()\n",
    "gf.biospecimen = samp\n",
    "gf.sequencing_experiment = seq_exp\n",
    "p.biospecimens = [samp]\n",
    "diag = Diagnosis()\n",
    "p.diagnoses = [diag]\n",
    "outcome = Outcome()\n",
    "p.outcomes = [outcome]\n",
    "phen = Phenotype()\n",
    "p.phenotypes = [phen]\n",
    "\n",
    "db.session.add(p)\n",
    "db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
