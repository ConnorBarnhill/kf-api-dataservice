{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from importlib import import_module\n",
    "\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from sqlalchemy.orm import joinedload, subqueryload, Load, load_only\n",
    "from sqlalchemy.orm.exc import NoResultFound\n",
    "from sqlalchemy.dialects import postgresql\n",
    "\n",
    "from dataservice.extensions import db\n",
    "from dataservice.utils import iterate_pairwise\n",
    "from dataservice import create_app\n",
    "from dataservice.api.investigator.models import Investigator\n",
    "from dataservice.api.study.models import Study\n",
    "from dataservice.api.participant.models import Participant\n",
    "from dataservice.api.biospecimen.models import Biospecimen\n",
    "from dataservice.api.family.models import Family\n",
    "from dataservice.api.family_relationship.models import FamilyRelationship\n",
    "from dataservice.api.diagnosis.models import Diagnosis\n",
    "from dataservice.api.outcome.models import Outcome\n",
    "from dataservice.api.phenotype.models import Phenotype\n",
    "from dataservice.api.genomic_file.models import GenomicFile\n",
    "from dataservice.api.sequencing_experiment.models import SequencingExperiment\n",
    "from dataservice.api.workflow.models import Workflow, WorkflowGenomicFile\n",
    "from dataservice.api.study_file.models import StudyFile\n",
    "\n",
    "from dataservice.util.data_import.utils import to_camel_case\n",
    "from dataservice.util.data_import.etl.defaults import DEFAULT_ENTITY_TYPES\n",
    "\n",
    "study_id = 'SD_FN5YSGZE'\n",
    "\n",
    "class BaseLoader(object):\n",
    "\n",
    "    def __init__(self, config_name=None):\n",
    "        if not config_name:\n",
    "            config_name = 'testing'\n",
    "        self.setup(config_name)\n",
    "        self.entity_id_map = {}\n",
    "\n",
    "    def setup(self, config_name):\n",
    "        \"\"\"\n",
    "        Creates tables in database\n",
    "        \"\"\"\n",
    "        self.app = create_app(config_name)\n",
    "        self.app.config['SQLALCHEMY_ECHO'] = True\n",
    "        self.app_context = self.app.app_context()\n",
    "        self.app_context.push()\n",
    "        db.drop_all()\n",
    "        db.create_all()\n",
    "#         self.import_models()\n",
    "\n",
    "    def teardown(self):\n",
    "        \"\"\"\n",
    "        Clean up\n",
    "        \"\"\"\n",
    "        db.session.close()\n",
    "        db.drop_all()\n",
    "\n",
    "    def drop_all(self, study_external_id):\n",
    "        \"\"\"\n",
    "        Delete all data related to a study\n",
    "        \"\"\"\n",
    "        from dataservice.api.study.models import Study\n",
    "        from dataservice.api.investigator.models import Investigator\n",
    "\n",
    "        try:\n",
    "            study = Study.query.filter_by(external_id=study_external_id).one()\n",
    "        except NoResultFound:\n",
    "            print(\"Study {} not found. Aborting drop all for this dataset\"\n",
    "                  .format(study_external_id))\n",
    "        else:\n",
    "            # Save investigator id\n",
    "            investigator_id = study.investigator_id\n",
    "\n",
    "            # Delete study\n",
    "            db.session.delete(study)\n",
    "\n",
    "            # Delete investigator\n",
    "            if investigator_id:\n",
    "                investigator = Investigator.query.get(investigator_id)\n",
    "                db.session.delete(investigator)\n",
    "\n",
    "            db.session.commit()\n",
    "\n",
    "    def import_models(self, skip_entities=[]):\n",
    "        \"\"\"\n",
    "        Load all entities into db\n",
    "        \"\"\"\n",
    "        # For each entity type\n",
    "        for entity_type in DEFAULT_ENTITY_TYPES:\n",
    "            # Skip some entities\n",
    "            if entity_type in skip_entities:\n",
    "                continue\n",
    "            # Dynamically import entity model class\n",
    "            model_name = to_camel_case(entity_type)\n",
    "            model_module_path = 'dataservice.api.{}.models'.format(\n",
    "                entity_type)\n",
    "            models_module = import_module(model_module_path)\n",
    "            model = getattr(models_module, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = BaseLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a bunch of studies for pagination\n",
    "for i in range(101):\n",
    "    s = Study(external_id='Study_{}'.format(i))\n",
    "    db.session.add(s)\n",
    "db.session.commit()\n",
    "\n",
    "# Add a bunch of study files\n",
    "s0 = Study.query.filter_by(external_id='Study_0').one()\n",
    "s1 = Study.query.filter_by(external_id='Study_1').one()\n",
    "for i in range(101):\n",
    "    sf = StudyFile(file_name='blah', study_id=s0.kf_id)\n",
    "    db.session.add(sf)\n",
    "db.session.commit()\n",
    "\n",
    "# Add a bunch of investigators\n",
    "for _ in range(102):\n",
    "    inv = Investigator(name='test')\n",
    "    inv.studies.extend([s0, s1])\n",
    "    db.session.add(inv)\n",
    "db.session.commit()\n",
    "\n",
    "# Add a bunch of families\n",
    "families = []\n",
    "for i in range(101):\n",
    "    families.append(Family(external_id='Family_{}'.format(i)))\n",
    "db.session.add_all(families)\n",
    "db.session.commit()\n",
    "\n",
    "participants = []\n",
    "f0 = Family.query.filter_by(external_id='Family_0').one()\n",
    "f1 = Family.query.filter_by(external_id='Family_1').one()\n",
    "for i in range(102):\n",
    "    f = f0 if i < 50 else f1\n",
    "    s = s0 if i < 50 else s1\n",
    "    data = {\n",
    "        'external_id': \"test\",\n",
    "        'is_proband': True,\n",
    "        'consent_type': 'GRU-IRB',\n",
    "        'race': 'asian',\n",
    "        'ethnicity': 'not hispanic',\n",
    "        'gender': 'male'\n",
    "    }\n",
    "\n",
    "    p = Participant(**data, study_id=s.kf_id, family_id=f.kf_id)\n",
    "    samp = Biospecimen(analyte_type='an analyte')\n",
    "    se_kwargs = {\n",
    "        'external_id': 'se1',\n",
    "        'experiment_strategy': 'WGS',\n",
    "        'center': 'Baylor',\n",
    "        'is_paired_end': True,\n",
    "        'platform': 'Illumina'\n",
    "    }\n",
    "    seq_exp = SequencingExperiment(**se_kwargs)\n",
    "    gf = GenomicFile()\n",
    "    gf.biospecimen = samp\n",
    "    gf.sequencing_experiment = seq_exp\n",
    "    p.biospecimens = [samp]\n",
    "    diag = Diagnosis()\n",
    "    p.diagnoses = [diag]\n",
    "    outcome = Outcome()\n",
    "    p.outcomes = [outcome]\n",
    "    phen = Phenotype()\n",
    "    p.phenotypes = [phen]\n",
    "    participants.append(p)\n",
    "    db.session.add(p)\n",
    "db.session.commit()\n",
    "\n",
    "# Family relationships\n",
    "for participant, relative in iterate_pairwise(participants):\n",
    "    gender = participant.gender\n",
    "    rel = 'mother'\n",
    "    if gender == 'male':\n",
    "        rel = 'father'\n",
    "    r = FamilyRelationship(participant=participant, relative=relative,\n",
    "                           participant_to_relative_relation=rel)\n",
    "    db.session.add(r)\n",
    "db.session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_id = Study.query.filter_by(external_id='Study_0').one().kf_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong way to load children through joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (Diagnosis.query.options(joinedload(Diagnosis.participant, innerjoin=True).load_only('kf_id'))\n",
    "# .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    ".filter(Participant.study_id == study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (Diagnosis.query\n",
    "     .join(Participant.diagnoses)\n",
    "     .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "     .filter(Participant.study_id == study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = (Diagnosis.query\n",
    "#      .options(joinedload(Participant.diagnoses).load_only('kf_id')))\n",
    "#      .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "#      .filter(Participant.study_id == study_id))\n",
    "# print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = (GenomicFile.query.options(\n",
    "     joinedload(GenomicFile.sequencing_experiment).load_only(\"kf_id\")\n",
    "     .joinedload(SequencingExperiment.aliquot).load_only(\"kf_id\")\n",
    "     .joinedload(Aliquot.sample).load_only(\"kf_id\"))\n",
    "     .join(Sample.participant).options(Load(Participant).load_only(\"kf_id\", \"study_id\"))\n",
    "     .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct way to load children through joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genomic files\n",
    "q = (GenomicFile.query\n",
    "     .join(SequencingExperiment.genomic_files)\n",
    "     .join(Aliquot.sequencing_experiments)\n",
    "     .join(Sample.aliquots)\n",
    "     .join(Participant.samples)\n",
    "     .filter(Participant.study_id==study_id)\n",
    "    )\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participants\n",
    "q = (Participant.query\n",
    "                .options(joinedload(Participant.diagnoses)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.samples)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.phenotypes)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.outcomes)\n",
    "                        .load_only('kf_id')))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Family \n",
    "q = (Family.query\n",
    "     .join(Family.participants)\n",
    "    .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "    .filter(Participant.study_id==study_id)\n",
    "    .distinct(Family.kf_id)\n",
    "    .order_by(Family.kf_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family relationship\n",
    "q = (FamilyRelationship.query\n",
    "     .join(FamilyRelationship.participant)\n",
    "    .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "    .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Study File\n",
    "q = StudyFile.query.filter(StudyFile.study_id == study_id)\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "results = q.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigator\n",
    "q = (Investigator.query\n",
    "     .join(Investigator.studies)\n",
    "     .options(Load(Study).load_only('kf_id'))\n",
    "     .filter(Study.kf_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Genomic files\n",
    "q = (GenomicFile.query\n",
    "     .join(GenomicFile.biospecimen)\n",
    "     .join(Biospecimen.participant)\n",
    "     .options(Load(Participant).load_only(\"kf_id\", \"study_id\"))\n",
    "     .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biospecimen\n",
    "q = (Biospecimen.query\n",
    "     .join(Participant.biospecimens)\n",
    "      .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "      .filter(Participant.study_id == study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing experiment\n",
    "q = (SequencingExperiment.query\n",
    "     .join(SequencingExperiment.genomic_files)\n",
    "     .join(GenomicFile.biospecimen)\n",
    "     .join(Biospecimen.participant)\n",
    "     .options(Load(Participant).load_only(\"kf_id\", \"study_id\"))\n",
    "     .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))\n",
    "q.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
