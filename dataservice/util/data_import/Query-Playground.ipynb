{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from importlib import import_module\n",
    "\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from sqlalchemy.orm import joinedload, selectinload, subqueryload, Load, load_only\n",
    "from sqlalchemy.orm.exc import NoResultFound\n",
    "from sqlalchemy.dialects import postgresql\n",
    "\n",
    "from dataservice.extensions import db\n",
    "from dataservice import create_app\n",
    "from dataservice.api.investigator.models import Investigator\n",
    "from dataservice.api.study.models import Study\n",
    "from dataservice.api.participant.models import Participant\n",
    "from dataservice.api.family_relationship.models import FamilyRelationship\n",
    "from dataservice.api.diagnosis.models import Diagnosis\n",
    "from dataservice.api.outcome.models import Outcome\n",
    "from dataservice.api.phenotype.models import Phenotype\n",
    "from dataservice.api.sample.models import Sample\n",
    "from dataservice.api.aliquot.models import Aliquot\n",
    "from dataservice.api.sequencing_experiment.models import SequencingExperiment\n",
    "from dataservice.api.genomic_file.models import GenomicFile\n",
    "from dataservice.api.workflow.models import Workflow, WorkflowGenomicFile\n",
    "from dataservice.api.study_file.models import StudyFile\n",
    "\n",
    "from dataservice.util.data_import.utils import to_camel_case\n",
    "from dataservice.util.data_import.etl.defaults import DEFAULT_ENTITY_TYPES\n",
    "\n",
    "study_id = 'SD_PTCT829R'\n",
    "\n",
    "class BaseLoader(object):\n",
    "\n",
    "    def __init__(self, config_name=None):\n",
    "        if not config_name:\n",
    "            config_name = os.environ.get('FLASK_CONFIG', 'default')\n",
    "        self.setup(config_name)\n",
    "        self.entity_id_map = {}\n",
    "\n",
    "    def setup(self, config_name):\n",
    "        \"\"\"\n",
    "        Creates tables in database\n",
    "        \"\"\"\n",
    "        self.app = create_app(config_name)\n",
    "        self.app.config['SQLALCHEMY_ECHO'] = True\n",
    "        self.app_context = self.app.app_context()\n",
    "        self.app_context.push()\n",
    "        db.create_all()\n",
    "        self.import_models()\n",
    "\n",
    "    def teardown(self):\n",
    "        \"\"\"\n",
    "        Clean up\n",
    "        \"\"\"\n",
    "        db.session.remove()\n",
    "        self.app_context.pop()\n",
    "\n",
    "    def drop_all(self, study_external_id):\n",
    "        \"\"\"\n",
    "        Delete all data related to a study\n",
    "        \"\"\"\n",
    "        from dataservice.api.study.models import Study\n",
    "        from dataservice.api.investigator.models import Investigator\n",
    "\n",
    "        try:\n",
    "            study = Study.query.filter_by(external_id=study_external_id).one()\n",
    "        except NoResultFound:\n",
    "            print(\"Study {} not found. Aborting drop all for this dataset\"\n",
    "                  .format(study_external_id))\n",
    "        else:\n",
    "            # Save investigator id\n",
    "            investigator_id = study.investigator_id\n",
    "\n",
    "            # Delete study\n",
    "            db.session.delete(study)\n",
    "\n",
    "            # Delete investigator\n",
    "            if investigator_id:\n",
    "                investigator = Investigator.query.get(investigator_id)\n",
    "                db.session.delete(investigator)\n",
    "\n",
    "            db.session.commit()\n",
    "\n",
    "    def import_models(self, skip_entities=[]):\n",
    "        \"\"\"\n",
    "        Load all entities into db\n",
    "        \"\"\"\n",
    "        # For each entity type\n",
    "        for entity_type in DEFAULT_ENTITY_TYPES:\n",
    "            # Skip some entities\n",
    "            if entity_type in skip_entities:\n",
    "                continue\n",
    "            # Dynamically import entity model class\n",
    "            model_name = to_camel_case(entity_type)\n",
    "            model_module_path = 'dataservice.api.{}.models'.format(\n",
    "                entity_type)\n",
    "            models_module = import_module(model_module_path)\n",
    "            model = getattr(models_module, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-10 12:33:50,758 INFO sqlalchemy.engine.base.Engine select version()\n",
      "2018-04-10 12:33:50,761 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-04-10 12:33:50,766 INFO sqlalchemy.engine.base.Engine select current_schema()\n",
      "2018-04-10 12:33:50,767 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-04-10 12:33:50,772 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2018-04-10 12:33:50,773 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-04-10 12:33:50,775 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2018-04-10 12:33:50,777 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-04-10 12:33:50,780 INFO sqlalchemy.engine.base.Engine show standard_conforming_strings\n",
      "2018-04-10 12:33:50,781 INFO sqlalchemy.engine.base.Engine {}\n",
      "2018-04-10 12:33:50,784 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:50,786 INFO sqlalchemy.engine.base.Engine {'name': 'diagnosis'}\n",
      "2018-04-10 12:33:50,789 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:50,790 INFO sqlalchemy.engine.base.Engine {'name': 'genomic_file'}\n",
      "2018-04-10 12:33:50,793 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:50,797 INFO sqlalchemy.engine.base.Engine {'name': 'sequencing_experiment'}\n",
      "2018-04-10 12:33:50,957 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:50,964 INFO sqlalchemy.engine.base.Engine {'name': 'aliquot'}\n",
      "2018-04-10 12:33:50,981 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:50,991 INFO sqlalchemy.engine.base.Engine {'name': 'sample'}\n",
      "2018-04-10 12:33:51,016 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,022 INFO sqlalchemy.engine.base.Engine {'name': 'outcome'}\n",
      "2018-04-10 12:33:51,028 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,030 INFO sqlalchemy.engine.base.Engine {'name': 'phenotype'}\n",
      "2018-04-10 12:33:51,035 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,037 INFO sqlalchemy.engine.base.Engine {'name': 'participant'}\n",
      "2018-04-10 12:33:51,041 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,044 INFO sqlalchemy.engine.base.Engine {'name': 'study_file'}\n",
      "2018-04-10 12:33:51,047 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,048 INFO sqlalchemy.engine.base.Engine {'name': 'study'}\n",
      "2018-04-10 12:33:51,051 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,053 INFO sqlalchemy.engine.base.Engine {'name': 'investigator'}\n",
      "2018-04-10 12:33:51,057 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,060 INFO sqlalchemy.engine.base.Engine {'name': 'family_relationship'}\n",
      "2018-04-10 12:33:51,064 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,066 INFO sqlalchemy.engine.base.Engine {'name': 'workflow'}\n",
      "2018-04-10 12:33:51,069 INFO sqlalchemy.engine.base.Engine select relname from pg_class c join pg_namespace n on n.oid=c.relnamespace where pg_catalog.pg_table_is_visible(c.oid) and relname=%(name)s\n",
      "2018-04-10 12:33:51,070 INFO sqlalchemy.engine.base.Engine {'name': 'workflow_genomic_file'}\n"
     ]
    }
   ],
   "source": [
    "loader = BaseLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genomic files for study\n",
    "q = (Participant.query.filter_by(study_id=study_id).options(\n",
    "              selectinload(Participant.samples)\n",
    "              .load_only('kf_id')\n",
    "              .selectinload(Sample.aliquots)\n",
    "              .load_only('kf_id')\n",
    "              .selectinload(Aliquot.sequencing_experiments)\n",
    "              .load_only('kf_id')\n",
    "              .selectinload(SequencingExperiment.genomic_files)))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = q.all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pt in pts:\n",
    "    for sample in pt.samples:\n",
    "        for aliquot in sample.aliquots:\n",
    "            for seqexp in aliquot.sequencing_experiments:\n",
    "                for gf in seqexp.genomic_files:\n",
    "                        gf\n",
    "#                     print(gf.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q = (GenomicFile.query.options(\n",
    "     joinedload(GenomicFile.sequencing_experiment).load_only(\"kf_id\")\n",
    "     .joinedload(SequencingExperiment.aliquot).load_only(\"kf_id\")\n",
    "     .joinedload(Aliquot.sample).load_only(\"kf_id\"))\n",
    "     .join(Sample.participant).options(Load(Participant).load_only(\"kf_id\", \"study_id\"))\n",
    "     .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = q.all()\n",
    "for r in results:\n",
    "    print(r.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_q = \\\n",
    "\"\"\"\n",
    "select genomic_file.uuid AS genomic_file_uuid, genomic_file.created_at AS genomic_file_created_at, genomic_file.modified_at AS genomic_file_modified_at, genomic_file.file_name AS genomic_file_file_name, genomic_file.data_type AS genomic_file_data_type, genomic_file.file_format AS genomic_file_file_format, genomic_file.file_size AS genomic_file_file_size, genomic_file.file_url AS genomic_file_file_url, genomic_file.md5sum AS genomic_file_md5sum, genomic_file.controlled_access AS genomic_file_controlled_access, genomic_file.sequencing_experiment_id AS genomic_file_sequencing_experiment_id, genomic_file.kf_id AS genomic_file_kf_id  from genomic_file\n",
    "inner join sequencing_experiment on genomic_file.sequencing_experiment_id=sequencing_experiment.kf_id\n",
    "inner join aliquot on sequencing_experiment.aliquot_id=aliquot.kf_id\n",
    "inner join sample on aliquot.sample_id=sample.kf_id\n",
    "inner join participant on sample.participant_id=participant.kf_id\n",
    "where participant.study_id={};\n",
    "\"\"\".format(study_id)\n",
    "results = db.session.query(GenomicFile).from_statement(sql_q)\n",
    "for r in results:\n",
    "    print(r.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT diagnosis.uuid, diagnosis.created_at, diagnosis.modified_at, diagnosis.external_id, diagnosis.diagnosis, diagnosis.diagnosis_category, diagnosis.tumor_location, diagnosis.age_at_event_days, diagnosis.participant_id, diagnosis.kf_id, participant_1.kf_id \n",
      "FROM participant, diagnosis JOIN participant AS participant_1 ON participant_1.kf_id = diagnosis.participant_id \n",
      "WHERE participant.study_id = %(study_id_1)s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singhn4/backup-kf-api-dataservice/venv/lib/python3.6/site-packages/sqlalchemy/sql/base.py:528: SAWarning: Column 'kf_id' on table <sqlalchemy.sql.selectable.Select at 0x111d9c390; Select object> being replaced by Column('kf_id', KfId(length=11), table=<Select object>, primary_key=True, nullable=False), which has the same key.  Consider use_labels for select() statements.\n",
      "  (key, getattr(existing, 'table', None), value))\n"
     ]
    }
   ],
   "source": [
    "q = (Diagnosis.query.options(joinedload(Diagnosis.participant, innerjoin=True).load_only('kf_id'))\n",
    "# .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    ".filter(Participant.study_id == study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT diagnosis.uuid, diagnosis.created_at, diagnosis.modified_at, diagnosis.external_id, diagnosis.diagnosis, diagnosis.diagnosis_category, diagnosis.tumor_location, diagnosis.age_at_event_days, diagnosis.participant_id, diagnosis.kf_id \n",
      "FROM participant JOIN diagnosis ON participant.kf_id = diagnosis.participant_id \n",
      "WHERE participant.study_id = %(study_id_1)s\n"
     ]
    }
   ],
   "source": [
    "q = (Diagnosis.query\n",
    "     .join(Participant.diagnoses)\n",
    "     .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "     .filter(Participant.study_id == study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = (Diagnosis.query\n",
    "#      .options(joinedload(Participant.diagnoses).load_only('kf_id')))\n",
    "#      .options(Load(Participant).load_only('kf_id', 'study_id'))\n",
    "#      .filter(Participant.study_id == study_id))\n",
    "# print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong way to load children through joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT genomic_file.uuid, genomic_file.created_at, genomic_file.modified_at, genomic_file.file_name, genomic_file.data_type, genomic_file.file_format, genomic_file.file_size, genomic_file.file_url, genomic_file.md5sum, genomic_file.controlled_access, genomic_file.sequencing_experiment_id, genomic_file.kf_id, sequencing_experiment_1.kf_id, aliquot_1.kf_id, sample_1.kf_id \n",
      "FROM sample JOIN participant ON participant.kf_id = sample.participant_id, genomic_file LEFT OUTER JOIN sequencing_experiment AS sequencing_experiment_1 ON sequencing_experiment_1.kf_id = genomic_file.sequencing_experiment_id LEFT OUTER JOIN aliquot AS aliquot_1 ON aliquot_1.kf_id = sequencing_experiment_1.aliquot_id LEFT OUTER JOIN sample AS sample_1 ON sample_1.kf_id = aliquot_1.sample_id \n",
      "WHERE participant.study_id = %(study_id_1)s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singhn4/backup-kf-api-dataservice/venv/lib/python3.6/site-packages/sqlalchemy/sql/base.py:528: SAWarning: Column 'kf_id' on table <sqlalchemy.sql.selectable.Select at 0x1118fe630; Select object> being replaced by Column('kf_id', KfId(length=11), table=<Select object>, primary_key=True, nullable=False), which has the same key.  Consider use_labels for select() statements.\n",
      "  (key, getattr(existing, 'table', None), value))\n"
     ]
    }
   ],
   "source": [
    "q = (GenomicFile.query.options(\n",
    "     joinedload(GenomicFile.sequencing_experiment).load_only(\"kf_id\")\n",
    "     .joinedload(SequencingExperiment.aliquot).load_only(\"kf_id\")\n",
    "     .joinedload(Aliquot.sample).load_only(\"kf_id\"))\n",
    "     .join(Sample.participant).options(Load(Participant).load_only(\"kf_id\", \"study_id\"))\n",
    "     .filter(Participant.study_id==study_id))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct way to load children through joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT genomic_file.uuid, genomic_file.created_at, genomic_file.modified_at, genomic_file.file_name, genomic_file.data_type, genomic_file.file_format, genomic_file.file_size, genomic_file.file_url, genomic_file.md5sum, genomic_file.controlled_access, genomic_file.sequencing_experiment_id, genomic_file.kf_id \n",
      "FROM sequencing_experiment JOIN genomic_file ON sequencing_experiment.kf_id = genomic_file.sequencing_experiment_id, aliquot JOIN sequencing_experiment ON aliquot.kf_id = sequencing_experiment.aliquot_id, sample JOIN aliquot ON sample.kf_id = aliquot.sample_id, participant JOIN sample ON participant.kf_id = sample.participant_id \n",
      "WHERE participant.study_id = %(study_id_1)s\n"
     ]
    }
   ],
   "source": [
    "q = (GenomicFile.query\n",
    "     .join(SequencingExperiment.genomic_files)\n",
    "     .join(Aliquot.sequencing_experiments)\n",
    "     .join(Sample.aliquots)\n",
    "     .join(Participant.samples)\n",
    "     .filter(Participant.study_id==study_id)\n",
    "    )\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT participant.uuid, participant.created_at, participant.modified_at, participant.external_id, participant.family_id, participant.is_proband, participant.consent_type, participant.race, participant.ethnicity, participant.gender, participant.study_id, participant.kf_id, diagnosis_1.kf_id, sample_1.kf_id, outcome_1.kf_id, phenotype_1.kf_id \n",
      "FROM participant LEFT OUTER JOIN diagnosis AS diagnosis_1 ON participant.kf_id = diagnosis_1.participant_id LEFT OUTER JOIN sample AS sample_1 ON participant.kf_id = sample_1.participant_id LEFT OUTER JOIN outcome AS outcome_1 ON participant.kf_id = outcome_1.participant_id LEFT OUTER JOIN phenotype AS phenotype_1 ON participant.kf_id = phenotype_1.participant_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/singhn4/backup-kf-api-dataservice/venv/lib/python3.6/site-packages/sqlalchemy/sql/base.py:528: SAWarning: Column 'kf_id' on table <sqlalchemy.sql.selectable.Select at 0x111ddb4a8; Select object> being replaced by Column('kf_id', KfId(length=11), table=<Select object>, primary_key=True, nullable=False), which has the same key.  Consider use_labels for select() statements.\n",
      "  (key, getattr(existing, 'table', None), value))\n"
     ]
    }
   ],
   "source": [
    "# Participants\n",
    "q = (Participant.query\n",
    "                .options(joinedload(Participant.diagnoses)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.samples)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.phenotypes)\n",
    "                        .load_only('kf_id'))\n",
    "                .options(joinedload(Participant.outcomes)\n",
    "                        .load_only('kf_id')))\n",
    "print(q.statement.compile(dialect=postgresql.dialect()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
