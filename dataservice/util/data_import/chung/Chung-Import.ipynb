{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from dataservice.util.data_import.utils import (\n",
    "    read_json, \n",
    "    write_json, \n",
    "    cols_to_lower, \n",
    "    dropna_rows_cols,\n",
    "    reformat_column_names,\n",
    "    extract_uncompressed_file_ext\n",
    ")\n",
    "\n",
    "DATA_DIR = '/Users/singhn4/Projects/kids_first/data/Chung'\n",
    "DBGAP_DIR = os.path.join(DATA_DIR, 'dbgap')\n",
    "MANIFESTS_DIR = os.path.join(DATA_DIR, 'manifests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create study\n",
    "study = {\n",
    "    'data_access_authority': 'dbGaP',\n",
    "    'study_id': 'phs001110',\n",
    "    'study_version': 'v1.p1',\n",
    "    'study_name': 'Genomic Analysis of Congenital Diaphragmatic Hernia and Associated Congenital Anomalies',\n",
    "    'attribution': 'https://www.ncbi.nlm.nih.gov/projects/gap/cgi-bin/study.cgi?study_id=phs001110.v1.p1'\n",
    "}\n",
    "study_df = pd.DataFrame([study])\n",
    "study_df.to_csv(os.path.join(DATA_DIR, 'study.txt'))\n",
    "\n",
    "# Create investigator\n",
    "invest = {\n",
    "    'investigator_name': 'Wendy Chung',\n",
    "    'institution': 'Columbia University Health Sciences'\n",
    "}\n",
    "inv_df = pd.DataFrame([invest])\n",
    "inv_df.to_csv(os.path.join(DATA_DIR, 'investigator.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_study_file_data(filepaths=None):\n",
    "    \"\"\"\n",
    "    Read in raw study files\n",
    "    \"\"\"\n",
    "    if not filepaths:\n",
    "        filepaths = os.listdir(DBGAP_DIR)\n",
    "        filepaths.extend(os.listdir(MANIFESTS_DIR))\n",
    "\n",
    "    study_files = [{\"study_file_name\": f}\n",
    "                   for f in filepaths]\n",
    "    return pd.DataFrame(study_files)\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_study_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read study data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR,\n",
    "                                'study.txt')\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_investigator_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read investigator data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR,\n",
    "                                'investigator.txt')\n",
    "    df = pd.read_csv(filepath)\n",
    "\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_subject_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read subject data file\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, '4a_dbGaP_SubjectDS_corrected_7-16.xlsx')\n",
    "    df = pd.read_excel(filepath, dtype={'SUBJECT_ID': str})\n",
    "    # Decode consent ints to consent strings\n",
    "    def func(row): \n",
    "        _map = {1: \"Disease-Specific (Congenital Diaphragmatic Hernia, COL, GSO, RD) (DS-CDH-COL-GSO-RD)\"}\n",
    "        return _map.get(row['CONSENT'])\n",
    "    df['CONSENT'] = df.apply(func, axis=1)\n",
    "\n",
    "    # Decode affected status ints to strings\n",
    "    def func(row): \n",
    "        _map = {0:'unknown', 1: \"affected\", 2: \"unaffected\"}\n",
    "        return _map.get(row['AFFECTED_STATUS'])\n",
    "    df['AFFECTED_STATUS'] = df.apply(func, axis=1)\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_subject_attr_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read subject attributes file\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, '3a_dbGaP_SubjectAttributesDS_corrected.6.12.xlsx')\n",
    "    df = pd.read_excel(filepath, dtype={'SUBJECT_ID': str})\n",
    "    # Decode body_site chars to strings\n",
    "    def func(row): \n",
    "        _map = {'B':'blood', 'SK': 'skin', 'D': 'diaphragm', 'SV': 'saliva', 'A': 'amniocytes', 'M': 'amniocytes'}\n",
    "        return _map.get(row['body_site'])\n",
    "    df['body_site'] = df.apply(func, axis=1)\n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_family_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read pedigree data\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, '6a_dbGaP_PedigreeDS_corrected.6.12.xlsx')\n",
    "    df = pd.read_excel(filepath)\n",
    "    del df['SEX']\n",
    "    \n",
    "    return df\n",
    "\n",
    "@reformat_column_names\n",
    "# @dropna_rows_cols\n",
    "def read_sample_manifests():\n",
    "    \"\"\"\n",
    "    Read and combine all sample manifest sheets\n",
    "    \"\"\"\n",
    "    # Sample manifests\n",
    "    # Combine all sample manifest sheets\n",
    "    dfs = [pd.read_excel(os.path.join(MANIFESTS_DIR, filename))\n",
    "\n",
    "           for filename in os.listdir(MANIFESTS_DIR)\n",
    "\n",
    "           ]\n",
    "    df = pd.concat(dfs)\n",
    "    df = df[df['Sample ID'].notnull()]\n",
    "    df.rename(columns={'Alias.2': 'is_proband'}, inplace=True)\n",
    "    df['is_proband'] = df['is_proband'].apply(lambda x: True if x == 'Proband' else False)\n",
    "    \n",
    "    def func(row):\n",
    "        val = str(row['Volume']).strip(\"uL\")\n",
    "        try:\n",
    "            val = int(val)\n",
    "        except ValueError:\n",
    "            val = np.NaN\n",
    "        return val\n",
    "    \n",
    "    df['Volume'] = df.apply(func, axis=1)\n",
    "    \n",
    "    def func(row):\n",
    "        val = str(row['Concentration']).strip(\"ng/uL\")\n",
    "        try:\n",
    "            val = int(val)\n",
    "        except ValueError:\n",
    "            val = np.NaN\n",
    "        return val\n",
    "    \n",
    "    df['Concentration'] = df.apply(func, axis=1)\n",
    "    \n",
    "    df = df[pd.notnull(df.Concentration)]\n",
    "    df = df[pd.notnull(df.Volume)]\n",
    "    df.Concentration = df.Concentration.astype('int')\n",
    "    df.Volume = df.Volume.astype('int')\n",
    "    \n",
    "    return df[['Concentration', 'Volume', 'Sample ID', 'Sample Type', 'is_proband']]\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_subject_sample_data(filepath=None):\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, '5a_dbGaP_SubjectSampleMappingDS cumulative.xlsx')\n",
    "    return pd.read_excel(filepath, delimiter='\\t')\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_demographic_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read demographic data from phenotype file\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, '2a_dbGaP_SubjectPhenotypesDS.xlsx')\n",
    "    df = pd.read_excel(filepath)\n",
    "    # Make all values lower case\n",
    "    for col in ['Ethnicity', 'Race']:\n",
    "        df[col] = df[col].apply(lambda x: str(x).lower().strip())\n",
    "        \n",
    "    return df[['SUBJECT_ID', 'SEX', 'Ethnicity', 'Race']]\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_phenotype_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read phenotype file and insert HPO IDs\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, '2a_dbGaP_SubjectPhenotypesDS.xlsx')\n",
    "\n",
    "    df = pd.read_excel(filepath)\n",
    "    df.drop(['Ethnicity', 'Race', 'SEX', 'discharge_status', 'ISOLATED'], inplace=True, axis=1)\n",
    "    # Reshape to build the phenotypes df\n",
    "    cols = df.columns.tolist()[1:]\n",
    "    phenotype_df = pd.melt(df, id_vars='SUBJECT_ID', value_vars=cols,\n",
    "                           var_name='phenotype', value_name='value')\n",
    "\n",
    "    # Drop rows where value is NaN\n",
    "    phenotype_df = phenotype_df[pd.notnull(phenotype_df['value'])]\n",
    "\n",
    "    # Decode phenotypes to descriptive strings\n",
    "    def func(row):\n",
    "        _map = {0: 'no', 1: 'yes'}\n",
    "        return _map.get(row['value'], row['value'])\n",
    "    phenotype_df['value'] = phenotype_df.apply(func, axis=1)\n",
    "\n",
    "    # Decode phenotypes to descriptive strings\n",
    "    def func(row):\n",
    "        # Always take most specific value\n",
    "        if row['value'] not in ['yes', 'no']:\n",
    "            val = row['value']\n",
    "        else:\n",
    "            _map = {'CHD': 'congenital heart defect', 'CNS': 'central nervous system defect', \n",
    "                'GI': 'gastrointestinal defect'}\n",
    "            val = _map.get(row['phenotype'], 'congenital birth defect')\n",
    "        return val\n",
    "    phenotype_df['phenotype'] = phenotype_df.apply(func, axis=1)\n",
    "\n",
    "    # Set observed\n",
    "    phenotype_df['observed'] = phenotype_df['value'].apply(lambda x: 'positive' if x != 'no' else 'negative')\n",
    "    del phenotype_df['value']\n",
    "    \n",
    "    # Add HPOs\n",
    "    from dataservice.util.data_import.etl.hpo import mapper\n",
    "    hpo_mapper = mapper.HPOMapper(DATA_DIR)\n",
    "    phenotype_df = hpo_mapper.add_hpo_id_col(phenotype_df)\n",
    "    \n",
    "    # Add unique col\n",
    "    def func(row): return \"_\".join(['phenotype', str(row.name)])\n",
    "    phenotype_df['phenotype_id'] = phenotype_df.apply(func, axis=1)\n",
    "    \n",
    "    return phenotype_df\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_outcome_data(filepath=None):\n",
    "    \"\"\"\n",
    "    Read outcome data from phenotype file\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DBGAP_DIR, '2a_dbGaP_SubjectPhenotypesDS.xlsx')\n",
    "    df = pd.read_excel(filepath)\n",
    "    \n",
    "    # Replace NaN values with None\n",
    "    df['discharge_status'] = df['discharge_status'].where((pd.notnull(df['discharge_status'])),999)\n",
    "    \n",
    "    # Map discharge status\n",
    "    # 1=Alive 4=Deceased 0=Fetal sample 8=unknown NA=Not applicable\n",
    "    def func(row): \n",
    "        _map = {0:'alive', 1: 'deceased', 4:'fetal sample', 8: 'unknown'}\n",
    "        return _map.get(int(row['discharge_status']), 'not applicable')\n",
    "    df['discharge_status'] = df.apply(func, axis=1)\n",
    "    \n",
    "    # Add unique col\n",
    "    def func(row): return \"_\".join(['outcome', str(row.name)])\n",
    "    df['outcome_id'] = df.apply(func, axis=1)\n",
    "    \n",
    "    return df[['SUBJECT_ID', 'discharge_status', 'outcome_id']]\n",
    "\n",
    "@reformat_column_names\n",
    "@dropna_rows_cols\n",
    "def read_genomic_file_manifest(filepath=None):\n",
    "    \"\"\"\n",
    "    Read genomic file manifest (ties subjects to genomic files)\n",
    "    \"\"\"\n",
    "    if not filepath:\n",
    "        filepath = os.path.join(DATA_DIR, 'sample.txt')\n",
    "\n",
    "    df = pd.read_csv(filepath, delimiter='\\t')\n",
    "    return df[['entity:sample_id', 'aligned_reads', 'crai_or_bai_path', 'cram_or_bam_path', \n",
    "               'library-1_name', 'library-2_name', 'max_insert_size', 'mean_depth', 'mean_insert_size', \n",
    "               'mean_read_length','min_insert_size', 'sample_alias', 'total_reads']]\n",
    "    \n",
    "HARMONIZED_TYPES = {'aligned reads'}\n",
    "def read_genomic_files_info(filepath):\n",
    "    \"\"\"\n",
    "    Read genomic file info json produced by Gen3 registration\n",
    "    and convert into genomic file table for dataservice\n",
    "    \"\"\"\n",
    "    data = read_json(filepath)\n",
    "    df = pd.DataFrame(list(data.values()))\n",
    "\n",
    "    # Reformat\n",
    "    df['md5sum'] = df['hashes'].apply(lambda x: x['md5'])\n",
    "    df['file_url'] = df['urls'].apply(lambda x: x[0])\n",
    "    df['file_name'] = df['file_url'].apply(\n",
    "        lambda file_url: os.path.basename(file_url))\n",
    "    df['file_format'] = df['file_name'].apply(\n",
    "        extract_uncompressed_file_ext)\n",
    "    df.rename(columns={'did': 'latest_did', 'size': 'file_size'},\n",
    "              inplace=True)\n",
    "\n",
    "    # Data type\n",
    "    def func(x):\n",
    "        x = x.strip()\n",
    "        if x.endswith('cram') or x.endswith('bam'):\n",
    "            val = 'submitted aligned reads'\n",
    "        elif x.endswith('crai'):\n",
    "            val = 'submitted aligned reads index'\n",
    "        elif 'fastq' in x:\n",
    "            val = 'submitted reads'\n",
    "        elif 'vcf' in x:\n",
    "            val = 'simple nucleotide variation'\n",
    "        else:\n",
    "            val = None\n",
    "        return val\n",
    "    df['data_type'] = df['file_name'].apply(func)\n",
    "\n",
    "    # Is harmonized\n",
    "    df['is_harmonized'] = df['data_type'].apply(\n",
    "        lambda data_type: True if data_type in HARMONIZED_TYPES else False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Db gap files\n",
    "files = {f:os.path.join(DBGAP_DIR, f) for f in os.listdir(DBGAP_DIR)}\n",
    "pprint(list(files.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of data\n",
    "df1 = pd.read_excel(files['4b_dbGaP_SubjectDD_corrected_6_12.xlsx'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject data\n",
    "df = pd.read_excel(files['4a_dbGaP_SubjectDS_corrected_7-16.xlsx'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['CONSENT'].unique())\n",
    "print(df['AFFECTED_STATUS'].unique())\n",
    "df.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject attributes data description\n",
    "df = pd.read_excel(files['3b_dbGaP_SubjectAttributesDD.xlsx'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject attributes\n",
    "df = pd.read_excel(files['3a_dbGaP_SubjectAttributesDS_corrected.6.12.xlsx'], delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.body_site.unique())\n",
    "df.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family/Pedigree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data description\n",
    "df = pd.read_excel(files['6b_dbGaP_PedigreeDD.xlsx'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(files['6a_dbGaP_PedigreeDS_corrected.6.12.xlsx'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data description\n",
    "df = pd.read_excel(files['2b_dbGaP_SubjectPhenotypesDD.xlsx'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "df = pd.read_excel(files['2a_dbGaP_SubjectPhenotypesDS.xlsx'], delimiter='\\t', dtype={'SUBJID': str})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject sample data description\n",
    "filepath = os.path.join(DBGAP_DIR, '5b_dbGaP_SubjectSampleMappingDD.xlsx')\n",
    "df = pd.read_excel(filepath, delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject sample mapping\n",
    "filepath = os.path.join(DBGAP_DIR, '5a_dbGaP_SubjectSampleMappingDS cumulative.xlsx')\n",
    "df = pd.read_excel(filepath, delimiter='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=['O']).T.sort_values('unique', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample manifests\n",
    "# Combine all sample manifest sheets\n",
    "dfs = [pd.read_excel(os.path.join(MANIFESTS_DIR, filename))\n",
    "\n",
    "       for filename in os.listdir(MANIFESTS_DIR)\n",
    "\n",
    "       ]\n",
    "df = pd.concat(dfs)\n",
    "df = df[df['Sample ID'].notnull()]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phenotype sheets\n",
    "dfs = [pd.read_excel(os.path.join(MANIFESTS_DIR, filename), sheet_name=1)\n",
    "\n",
    "       for filename in os.listdir(MANIFESTS_DIR)\n",
    "\n",
    "       ]\n",
    "df = pd.concat(dfs)\n",
    "df = df[df['Sample ID'].notnull()]\n",
    "# Make all values lower case\n",
    "df['Primary Disease'] = df['Primary Disease'].apply(lambda x: str(x).lower())\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participants, Family Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_df = read_subject_data()\n",
    "print(subject_df.nunique())\n",
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_attr_df = read_subject_attr_data()\n",
    "print(subject_attr_df.nunique())\n",
    "subject_attr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_df = read_family_data()\n",
    "family_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_manifest_df = read_sample_manifests()\n",
    "print(sample_manifest_df.nunique())\n",
    "sample_manifest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Participant df\n",
    "# Merge subject + subject attributes\n",
    "df1 = pd.merge(subject_df, subject_attr_df, on='subject_id')\n",
    "df1.head()\n",
    "\n",
    "# Merge family\n",
    "df2 = pd.merge(df1, family_df, on='subject_id')\n",
    "print('{} Participants w/o samples merged'.format(df2.shape))\n",
    "\n",
    "# Merge proband from sample manifests\n",
    "participant_df = pd.merge(df2, sample_manifest_df[['sample_id', 'is_proband']], how='left', on='sample_id')\n",
    "participant_df['is_proband'].fillna(False, inplace=True)\n",
    "print('{} Participants w samples merged'.format(participant_df.shape))\n",
    "participant_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demographic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df = read_demographic_data()\n",
    "demographic_df = pd.merge(demographic_df, participant_df, on='subject_id')\n",
    "demographic_df.head()\n",
    "demographic_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_manifest_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject sample mappings\n",
    "subject_sample_df = read_subject_sample_data()\n",
    "subject_sample_df.head()\n",
    "\n",
    "# Merge with subject data\n",
    "df3 = pd.merge(participant_df, subject_sample_df[['subject_id', 'sample_use']], on='subject_id')\n",
    "print(df3.shape)\n",
    "\n",
    "# Merge with sample manifests\n",
    "sample_df = pd.merge(df3, sample_manifest_df, how='left', on='sample_id')\n",
    "print(sample_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genomic Files, Seq Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencing experiments\n",
    "gf_manifest_df = read_genomic_file_manifest()\n",
    "print(gf_manifest_df.nunique())\n",
    "gf_manifest_df.head()\n",
    "# gf_manifest_df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genomic file df\n",
    "gf_file_info_df = read_genomic_files_info()\n",
    "gf_file_info_df['subject_id'] = gf_file_info_df['file_name'].apply(lambda file_name: file_name.split('.')[0])\n",
    "print(gf_file_info_df.shape)\n",
    "gf_file_info_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf_file_info_df[['uuid', 'file_name', 'subject_id']].describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with biospecimens\n",
    "df = pd.merge(sample_df[['subject_id', 'sample_id']], gf_file_info_df, on='subject_id')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with sequencing experiments\n",
    "genomic_file_df = pd.merge(df, gf_manifest_df, left_on='subject_id', right_on='sample_alias')\n",
    "print(genomic_file_df.shape)\n",
    "genomic_file_df.head()\n",
    "# genomic_file_df.describe(include='O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read phenotype\n",
    "phenotype_df = read_phenotype_data()\n",
    "phenotype_df.head()\n",
    "\n",
    "# Merge with participant df\n",
    "phenotype_df = pd.merge(phenotype_df, participant_df, on='subject_id')\n",
    "phenotype_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenos = phenotype_df[phenotype_df.observed == 'positive']\n",
    "phenos.groupby(['phenotype']).count().sort_values(['phenotype_id'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = read_outcome_data()\n",
    "outcome_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = outcome_df[outcome_df.discharge_status != 'not applicable']\n",
    "outcome_df.discharge_status.unique()\n",
    "outcome_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
